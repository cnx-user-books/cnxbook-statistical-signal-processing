<document xmlns="http://cnx.rice.edu/cnxml" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:md="http://cnx.rice.edu/mdml">
  <title>Minimum Probability of Error Decision Rule</title>
  <metadata><md:content-id>undefined</md:content-id><md:title/><md:uuid>235164b4-55fc-4fc0-8bf4-67880397d188</md:uuid>
</metadata>

  <content>
    <para id="para1">Consider the binary hypothesis test
      <m:math display="block">
	<m:mrow>
	  <m:msub>
	    <m:mi>ℋ</m:mi>
	    <m:mn>0</m:mn>
	  </m:msub>
	  <m:mo>:</m:mo>
	  <m:apply>
	    <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#distributedin"/>
	    <m:ci type="vector">x</m:ci>
	    <m:apply>
	      <m:ci type="fn"><m:msub>
		  <m:mi>f</m:mi>
		  <m:mn>0</m:mn>
		</m:msub></m:ci>
	      <m:ci type="vector">x</m:ci>
	    </m:apply>
	  </m:apply>
	</m:mrow>
      </m:math>
      <m:math display="block">
	<m:mrow>
	  <m:msub>
	    <m:mi>ℋ</m:mi>
	    <m:mn>1</m:mn>
	  </m:msub>
	  <m:mo>:</m:mo>
	  <m:apply>
	    <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#distributedin"/>
	    <m:ci type="vector">x</m:ci>
	    <m:apply>
	      <m:ci type="fn"><m:msub>
		  <m:mi>f</m:mi>
		  <m:mn>1</m:mn>
		</m:msub></m:ci>
	      <m:ci type="vector">x</m:ci>
	    </m:apply>
	  </m:apply>
	</m:mrow>
      </m:math>
      Let
      <m:math>
	<m:ci><m:msub>
	    <m:mi>π</m:mi>
	    <m:mi>i</m:mi>
	  </m:msub></m:ci>
      </m:math>, denote the <foreign>a priori</foreign> probability of
      hypothesis
      <m:math>
	<m:ci><m:msub>
	    <m:mi>ℋ</m:mi>
	    <m:mi>i</m:mi>
	  </m:msub></m:ci>
      </m:math>. Suppose our decision rule declares 
      "<m:math>
	<m:ci><m:msub>
	    <m:mi>ℋ</m:mi>
	    <m:mn>0</m:mn>
	  </m:msub></m:ci>
      </m:math> is the true model" when
      <m:math>
	<m:apply>
	  <m:in/>
	  <m:ci type="vector">x</m:ci>
	  <m:ci><m:msub>
	      <m:mi>R</m:mi>
	      <m:mn>0</m:mn>
	    </m:msub></m:ci>
	</m:apply>
      </m:math>, and it selects
      <m:math>
	<m:ci><m:msub>
	    <m:mi>ℋ</m:mi>
	    <m:mn>1</m:mn>
	  </m:msub></m:ci>
      </m:math>
      when 
      <m:math>
	<m:apply>
	  <m:in/>
	  <m:ci type="vector">x</m:ci>
	  <m:ci><m:msub>
	      <m:mi>R</m:mi>
	      <m:mn>1</m:mn>
	    </m:msub></m:ci>
	</m:apply>
      </m:math>, where
      <m:math>
	<m:apply>
	  <m:eq/>
	  <m:ci><m:msub>
	      <m:mi>R</m:mi>
	      <m:mn>1</m:mn>
	    </m:msub></m:ci>
	  <m:apply>
	    <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#complement"/>
	    <m:ci><m:msub>
		<m:mi>R</m:mi>
		<m:mn>0</m:mn>
	      </m:msub></m:ci>
	  </m:apply>
	</m:apply>
      </m:math>. The probability of making an error, denoted
      <m:math>
	<m:ci><m:msub>
	    <m:mi>P</m:mi>
	    <m:mi>e</m:mi>
	  </m:msub></m:ci>
      </m:math>, is
      <equation id="eqn1">
      <m:math>
	<m:apply>
	  <m:eq/>
	  <m:ci><m:msub>
	      <m:mi>P</m:mi>
	      <m:mi>e</m:mi>
	    </m:msub></m:ci>

	  <m:apply>
	    <m:plus/>
	    <m:apply>
	      <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#probability"/>
	      <m:mrow>
		<m:mtext>declare </m:mtext>
		<m:msub>
		  <m:mi>ℋ</m:mi>
		  <m:mn>0</m:mn>
		</m:msub>
		<m:mtext> and </m:mtext>
		<m:msub>
		  <m:mi>ℋ</m:mi>
		  <m:mn>1</m:mn>
		</m:msub>
		<m:mtext> true</m:mtext>
	      </m:mrow>
	    </m:apply>
	    <m:apply>
	      <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#probability"/>
	      <m:mrow>
		<m:mtext>declare </m:mtext>
		<m:msub>
		  <m:mi>ℋ</m:mi>
		  <m:mn>1</m:mn>
		</m:msub>
		<m:mtext> and </m:mtext>
		<m:msub>
		  <m:mi>ℋ</m:mi>
		  <m:mn>0</m:mn>
		</m:msub>
		<m:mtext> true</m:mtext>
	      </m:mrow>
	    </m:apply>
	  </m:apply>

	  <m:apply>
	    <m:plus/>
	    <m:apply>
	      <m:times/>
	      <m:apply>
		<m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#probability"/>
		<m:ci><m:msub>
		    <m:mi>ℋ</m:mi>
		    <m:mn>1</m:mn>
		  </m:msub></m:ci>
	      </m:apply>
	      <m:apply>
		<m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#probability"/>
		<m:condition>
		  <m:ci><m:msub>
		      <m:mi>ℋ</m:mi>
		      <m:mn>1</m:mn>
		    </m:msub></m:ci>
		</m:condition>
		<m:ci><m:msub>
		    <m:mi>ℋ</m:mi>
		    <m:mn>0</m:mn>
		  </m:msub></m:ci>
	      </m:apply>
	    </m:apply>
	    <m:apply>
	      <m:times/>
	      <m:apply>
		<m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#probability"/>
		<m:ci><m:msub>
		    <m:mi>ℋ</m:mi>
		    <m:mn>0</m:mn>
		  </m:msub></m:ci>
	      </m:apply>
	      <m:apply>
		<m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#probability"/>
		<m:condition>
		  <m:ci><m:msub>
		      <m:mi>ℋ</m:mi>
		      <m:mn>0</m:mn>
		    </m:msub></m:ci>
		</m:condition>
		<m:ci><m:msub>
		    <m:mi>ℋ</m:mi>
		    <m:mn>1</m:mn>
		  </m:msub></m:ci>
	      </m:apply>
	    </m:apply>
	  </m:apply>

	  <m:apply>
	    <m:plus/>
	      <m:apply>
		<m:int/>
		<m:bvar>
		  <m:ci type="vector">x</m:ci>
		</m:bvar>
		<m:domainofapplication>
		  <m:ci><m:msub>
		      <m:mi>R</m:mi>
		      <m:mn>0</m:mn>
		    </m:msub></m:ci>
		</m:domainofapplication>
		<m:apply>
		  <m:times/>
		  <m:ci><m:msub>
		      <m:mi>π</m:mi>
		      <m:mn>1</m:mn>
		    </m:msub></m:ci>
		  <m:apply>
		    <m:ci type="fn"><m:msub>
			<m:mi>f</m:mi>
			<m:mn>1</m:mn>
		      </m:msub></m:ci>
		    <m:ci type="vector">x</m:ci>
		  </m:apply>
		</m:apply>
	      </m:apply>
	      <m:apply>
		<m:int/>
		<m:bvar>
		  <m:ci type="vector">x</m:ci>
		</m:bvar>
		<m:domainofapplication>
		  <m:ci><m:msub>
		      <m:mi>R</m:mi>
		      <m:mn>1</m:mn>
		    </m:msub></m:ci>
		</m:domainofapplication>
		<m:apply>
		  <m:times/>
		  <m:ci><m:msub>
		      <m:mi>π</m:mi>
		      <m:mn>0</m:mn>
		    </m:msub></m:ci>
		  <m:apply>
		    <m:ci type="fn"><m:msub>
			<m:mi>f</m:mi>
			<m:mn>0</m:mn>
		      </m:msub></m:ci>
		    <m:ci type="vector">x</m:ci>
		  </m:apply>
		</m:apply>
	      </m:apply>
	    </m:apply>
	  </m:apply>
	</m:math>
      </equation>
      In this module, we study the minimum probability of error
      decision rule, which selects
      <m:math>
	<m:ci><m:msub>
	    <m:mi>R</m:mi>
	    <m:mn>0</m:mn>
	  </m:msub></m:ci>
      </m:math> and
      <m:math>
	<m:ci><m:msub>
	    <m:mi>R</m:mi>
	    <m:mn>1</m:mn>
	  </m:msub></m:ci>
      </m:math> so as to minimize the above expression.
    </para>   

    <para id="para2">Since an observation <m:math><m:ci type="vector">x</m:ci></m:math> falls into one and only one of the
    decision regions
      <m:math>
	<m:ci><m:msub>
	    <m:mi>R</m:mi>
	    <m:mi>i</m:mi>
	  </m:msub></m:ci>
      </m:math>, in order to minimize
      <m:math>
	<m:ci><m:msub>
	    <m:mi>P</m:mi>
	    <m:mi>e</m:mi>
	  </m:msub></m:ci>
      </m:math>, 
      we assign <m:math><m:ci type="vector">x</m:ci></m:math> to the
      region for which the corresponding integrand in <link target-id="eqn1"/>
      is smaller. Thus, we select
      <m:math>
	<m:apply>
	  <m:in/>
	  <m:ci type="vector">x</m:ci>
	  <m:ci><m:msub>
	      <m:mi>R</m:mi>
	      <m:mn>0</m:mn>
	    </m:msub></m:ci>
	</m:apply>
      </m:math> if 
      <m:math>
	<m:apply>
	  <m:lt/>
	  <m:apply>
	    <m:times/>
	    <m:ci><m:msub>
		<m:mi>π</m:mi>
		<m:mn>1</m:mn>
	      </m:msub></m:ci>
	    <m:apply>
	      <m:ci type="fn"><m:msub>
		  <m:mi>f</m:mi>
		  <m:mn>1</m:mn>
		</m:msub></m:ci>
	      <m:ci type="vector">x</m:ci>
	    </m:apply>
	  </m:apply>
	  <m:apply>
	    <m:times/>
	    <m:ci><m:msub>
		<m:mi>π</m:mi>
		<m:mn>0</m:mn>
	      </m:msub></m:ci>
	    <m:apply>
	      <m:ci type="fn"><m:msub>
		  <m:mi>f</m:mi>
		  <m:mn>0</m:mn>
		</m:msub></m:ci>
	      <m:ci type="vector">x</m:ci>
	    </m:apply>
	  </m:apply>
	</m:apply>
      </m:math>, and 
      <m:math>
	<m:apply>
	  <m:in/>
	  <m:ci type="vector">x</m:ci>
	  <m:ci><m:msub>
	      <m:mi>R</m:mi>
	      <m:mn>1</m:mn>
	    </m:msub></m:ci>
	</m:apply>
      </m:math> if the inequality is reversed. This decision rule may
      be summarized concisely as
      <m:math display="block">
	<m:mrow>
	  <m:apply>
	    <m:equivalent/>
	    <m:apply>
	      <m:ci type="fn">Λ</m:ci>
	      <m:ci type="vector">x</m:ci>
	    </m:apply>
	    <m:apply>
	      <m:divide/>
	      <m:apply>
		<m:ci type="fn"><m:msub>
		    <m:mi>f</m:mi>
		    <m:mn>1</m:mn>
		  </m:msub></m:ci>
		<m:ci type="vector">x</m:ci>
	      </m:apply>
	      <m:apply>
		<m:ci type="fn"><m:msub>
		    <m:mi>f</m:mi>
		    <m:mn>0</m:mn>
		  </m:msub></m:ci>
		<m:ci type="vector">x</m:ci>
	      </m:apply>
	    </m:apply>
	  </m:apply>

	  <m:munderover>
	    <m:mo>≷</m:mo>
	    <m:msub>
	      <m:mi>ℋ</m:mi>
	      <m:mn>0</m:mn>
	    </m:msub>
	    <m:msub>
	      <m:mi>ℋ</m:mi>
	      <m:mn>1</m:mn>
	    </m:msub>
	  </m:munderover>

	  <m:apply>
	    <m:equivalent/>
	    <m:apply>
	      <m:divide/>
	      <m:ci><m:msub>
		  <m:mi>π</m:mi>
		  <m:mn>0</m:mn>
		</m:msub></m:ci>
	      <m:ci><m:msub>
		  <m:mi>π</m:mi>
		  <m:mn>1</m:mn>
		</m:msub></m:ci>
	    </m:apply>
	    <m:mi>η</m:mi>
	  </m:apply>
	</m:mrow>
      </m:math>

      Here, 
      <m:math>
	<m:apply>
	  <m:ci type="fn">Λ</m:ci>
	  <m:ci type="vector">x</m:ci>
	</m:apply>
      </m:math> is called the <term>likelihood ratio</term>,
      <m:math><m:ci>η</m:ci></m:math> is called a
      <term>threshold</term>, and the overall decision rule is called
      the <link url="http://workshop.molecularevolution.org/resources/lrt.php">Likelihood Ratio Test</link>.
      
     
    </para>
  
    <example id="ex1">
      <section id="sec1ex1">
	<title>Normal with Common Variance, Uncommon Means</title>

	<para id="para1ex1">Consider the binary hypothesis test of a scalar 
	  <m:math><m:ci>x</m:ci></m:math>
	  <m:math display="block">
	    <m:mrow>
	      <m:msub>
		<m:mi>ℋ</m:mi>
		<m:mn>0</m:mn>
	      </m:msub>
	      <m:mo>:</m:mo>
	      <m:apply>
		<m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#distributedin"/>
		<m:ci>x</m:ci>
		<m:apply>
		  <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#normaldistribution"/>
		  <m:cn>0</m:cn>
		  <m:apply>
		    <m:power/>
		    <m:ci>σ</m:ci>
		    <m:cn>2</m:cn>
		  </m:apply>
		</m:apply>
	      </m:apply>
	    </m:mrow>
	  </m:math>
	  <m:math display="block">
	    <m:mrow>
	      <m:msub>
		<m:mi>ℋ</m:mi>
		<m:mn>1</m:mn>
	      </m:msub>
	      <m:mo>:</m:mo>
	      <m:apply>
		<m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#distributedin"/>
		<m:ci>x</m:ci>
		<m:apply>
		  <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#normaldistribution"/>
		  <m:ci>μ</m:ci>
		  <m:apply>
		    <m:power/>
		    <m:ci>σ</m:ci>
		    <m:cn>2</m:cn>
		  </m:apply>
		</m:apply>
	      </m:apply>
	    </m:mrow>
	  </m:math>
	  where <m:math><m:ci>μ</m:ci></m:math> and
	  <m:math>
	    <m:apply>
	      <m:power/>
	      <m:ci>σ</m:ci>
	      <m:cn>2</m:cn>
	    </m:apply>
	  </m:math> are known, positive quantities. Suppose we observe
	  a single measurement <m:math><m:ci>x</m:ci></m:math>. The
	  likelihood ratio is
	  <equation id="eqn2">
	  <m:math>
	    <m:apply>
	      <m:eq/>
	      <m:apply>
		<m:ci type="fn">Λ</m:ci>
		<m:ci>x</m:ci>
	      </m:apply>

	      <m:apply>
		<m:divide/>
		<m:apply>
		  <m:times/>
		  <m:apply>
		    <m:divide/>
		    <m:cn>1</m:cn>
		    <m:apply>
		      <m:root/>
		      <m:apply>
			<m:times/>
			<m:cn>2</m:cn>
			<m:pi/>
			<m:apply>
			  <m:power/>
			  <m:ci>σ</m:ci>
			  <m:cn>2</m:cn>
			</m:apply>
		      </m:apply>
		    </m:apply>
		  </m:apply>
		  <m:apply>
		    <m:exp/>
		    <m:apply>
		      <m:minus/>
		      <m:apply>
			<m:divide/>
			<m:apply>
			  <m:power/>
			  <m:apply>
			    <m:minus/>
			    <m:ci>x</m:ci>
			    <m:ci>μ</m:ci>
			  </m:apply>
			  <m:cn>2</m:cn>
			</m:apply>
			<m:apply>
			  <m:times/>
			  <m:cn>2</m:cn>
			  <m:apply>
			    <m:power/>
			    <m:ci>σ</m:ci>
			    <m:cn>2</m:cn>
			  </m:apply>
			</m:apply>
		      </m:apply>
		    </m:apply>
		  </m:apply>
		</m:apply>
		<m:apply>
		  <m:times/>
		  <m:apply>
		    <m:divide/>
		    <m:cn>1</m:cn>
		    <m:apply>
		      <m:root/>
		      <m:apply>
			<m:times/>
			<m:cn>2</m:cn>
			<m:pi/>
			<m:apply>
			  <m:power/>
			  <m:ci>σ</m:ci>
			  <m:cn>2</m:cn>
			</m:apply>
		      </m:apply>
		    </m:apply>
		  </m:apply>
		  <m:apply>
		    <m:exp/>
		    <m:apply>
		      <m:minus/>
		      <m:apply>
			<m:divide/>
			<m:apply>
			  <m:power/>
			  <m:ci>x</m:ci>
			  <m:cn>2</m:cn>
			</m:apply>
			<m:apply>
			  <m:times/>
			  <m:cn>2</m:cn>
			  <m:apply>
			    <m:power/>
			    <m:ci>σ</m:ci>
			    <m:cn>2</m:cn>
			  </m:apply>
			</m:apply>
		      </m:apply>
		    </m:apply>
		  </m:apply>
		</m:apply>
	      </m:apply>

	      <m:apply>
		<m:exp/>
		<m:apply>
		  <m:times/>
		  <m:apply>
		    <m:divide/>
		    <m:cn>1</m:cn>
		    <m:apply>
		      <m:power/>
		      <m:ci>σ</m:ci>
		      <m:cn>2</m:cn>
		    </m:apply>
		  </m:apply>
		  <m:apply>
		    <m:minus/>
		    <m:apply>
		      <m:times/>
		      <m:ci>μ</m:ci>
		      <m:ci>x</m:ci>
		    </m:apply>
		    <m:apply>
		      <m:divide/>
		      <m:apply>
			<m:power/>
			<m:ci>μ</m:ci>
			<m:cn>2</m:cn>
		      </m:apply>
		      <m:cn>2</m:cn>
		    </m:apply>
		  </m:apply>
		</m:apply>
	      </m:apply>
	    </m:apply>
	  </m:math>
	  </equation>
	  and so the minimum probability of error decision rule is
	  <m:math display="block">
	    <m:mrow>
	      <m:apply>
		<m:exp/>
		<m:apply>
		  <m:times/>
		  <m:apply>
		    <m:divide/>
		    <m:mn>1</m:mn>
		    <m:apply>
		      <m:power/>
		      <m:mi>σ</m:mi>
		      <m:mn>2</m:mn>
		    </m:apply>
		  </m:apply>
		  <m:apply>
		    <m:minus/>
		    <m:apply>
		      <m:times/>
		      <m:mi>μ</m:mi>
		      <m:mi>x</m:mi>
		    </m:apply>
		    <m:apply>
		      <m:divide/>
		      <m:apply>
			<m:power/>
			<m:mi>μ</m:mi>
			<m:mn>2</m:mn>
		      </m:apply>
		      <m:mn>2</m:mn>
		    </m:apply>
		  </m:apply>
		</m:apply>
	      </m:apply>

	      <m:munderover>
		<m:mo>≷</m:mo>
		<m:msub>
		  <m:mi>ℋ</m:mi>
		  <m:mn>0</m:mn>
		</m:msub>
		<m:msub>
		  <m:mi>ℋ</m:mi>
		  <m:mn>1</m:mn>
		</m:msub>
	      </m:munderover>

	      <m:apply>
		<m:eq/>
		<m:apply>
		  <m:divide/>
		  <m:msub>
		    <m:mi>π</m:mi>
		    <m:mn>0</m:mn>
		  </m:msub>
		  <m:msub>
		    <m:mi>π</m:mi>
		    <m:mn>1</m:mn>
		  </m:msub>
		</m:apply>
		<m:mi>η</m:mi>
	      </m:apply>
	    </m:mrow>
	  </m:math>
	
	  The expression for
	  <m:math>
	    <m:apply>
	      <m:ci type="fn">Λ</m:ci>
	      <m:ci>x</m:ci>
	    </m:apply>
	  </m:math> 
	  is somewhat complicated. By applying a sequence of
	  monotonically increasing functions to both sides, we can
	  obtain a simplified expression for the optimal decision rule
	  without changing the rule. In this example, we apply the
	  natural logarithm and rearrange terms to arrive at
	  <m:math display="block">
	    <m:mrow>
	      <m:mi>x</m:mi>

	      <m:munderover>
		<m:mo>≷</m:mo>
		<m:msub>
		  <m:mi>ℋ</m:mi>
		  <m:mn>0</m:mn>
		</m:msub>
		<m:msub>
		  <m:mi>ℋ</m:mi>
		  <m:mn>1</m:mn>
		</m:msub>
	      </m:munderover>

	      <m:apply>
		<m:equivalent/>
		<m:apply>
		  <m:plus/>
		  <m:apply>
		    <m:times/>
		    <m:apply>
		      <m:divide/>
		      <m:apply>
			<m:power/>
			<m:mi>σ</m:mi>
			<m:mn>2</m:mn>
		      </m:apply>
		      <m:mi>μ</m:mi>
		    </m:apply>
		    <m:apply>
		      <m:ln/>
		      <m:mi>η</m:mi>
		    </m:apply>
		  </m:apply>
		  <m:apply>
		    <m:divide/>
		    <m:mi>μ</m:mi>
		    <m:mn>2</m:mn>
		  </m:apply>
		</m:apply>
		<m:mi>γ</m:mi>
	      </m:apply>
	    </m:mrow>
	  </m:math>
	  Here we have used the assumption 
	  <m:math>
	    <m:apply>
	      <m:gt/>
	      <m:ci>μ</m:ci>
	      <m:cn>0</m:cn>
	    </m:apply>
	  </m:math>. If
	  <m:math>
	    <m:apply>
	      <m:lt/>
	      <m:ci>μ</m:ci>
	      <m:cn>0</m:cn>
	    </m:apply>
	  </m:math>, then dividing by <m:math><m:ci>μ</m:ci>
	  </m:math> would reverse the inequalities.
	</para>

	<para id="ex1para2">This form of the decision rule is much
	simpler: we just compare the observed value
	<m:math><m:ci>x</m:ci></m:math> to a threshold
	<m:math><m:ci>γ</m:ci></m:math>. <link target-id="fig1"/>
	depicts the two candidate densities and a possible value of
	<m:math><m:ci>γ</m:ci></m:math>. If each hypothesis is
	<foreign>a priori</foreign> equally likely
	  (<m:math>
	    <m:apply>
	      <m:eq/>
	      <m:ci><m:msub>
		  <m:mi>π</m:mi>
		  <m:mn>0</m:mn>
		</m:msub></m:ci>
	      <m:ci><m:msub>
		  <m:mi>π</m:mi>
		  <m:mn>1</m:mn>
		</m:msub></m:ci>
	      <m:apply>
		<m:divide/>
		<m:cn>1</m:cn>
		<m:cn>2</m:cn>
	      </m:apply>
	    </m:apply>
	  </m:math>), then
	  <m:math>
	    <m:apply>
	      <m:eq/>
	      <m:ci>γ</m:ci>
	      <m:apply>
		<m:divide/>
		<m:ci>μ</m:ci>
		<m:cn>2</m:cn>
	      </m:apply>
	    </m:apply>
	  </m:math>. <link target-id="fig1"/> illustrates the case where
	  <m:math>
	    <m:apply>
	      <m:gt/>
	      <m:ci><m:msub>
		  <m:mi>π</m:mi>
		  <m:mn>0</m:mn>
		</m:msub></m:ci>
	      <m:ci><m:msub>
		  <m:mi>π</m:mi>
		  <m:mn>1</m:mn>
		</m:msub></m:ci>
	    </m:apply>
	  </m:math>
	  (<m:math>
	    <m:apply>
	      <m:gt/>
	      <m:ci>γ</m:ci>
	      <m:apply>
		<m:divide/>
		<m:ci>μ</m:ci>
		<m:cn>2</m:cn>
	      </m:apply>
	    </m:apply>
	  </m:math>).

	   
	  <figure id="fig1" orient="vertical">
	    <subfigure id="sub1">
	      <media id="idm6206864" alt=""><image src="../../media/GaussUncMeanComVarPd.png" mime-type="image/png"/></media>
	    </subfigure>
	    <subfigure id="sub2">
	      <media id="idp2336544" alt=""><image src="../../media/GaussUncMeanComVarPf.png" mime-type="image/png"/></media>
	    </subfigure>
	    <caption>The two candidate densities, and a threshold
	    corresponding to
	      <m:math>
		<m:apply>
		  <m:gt/>
		  <m:ci><m:msub>
		      <m:mi>π</m:mi>
		      <m:mn>0</m:mn>
		    </m:msub></m:ci>
		  <m:ci><m:msub>
		      <m:mi>π</m:mi>
		      <m:mn>1</m:mn>
		    </m:msub></m:ci>
		</m:apply>
	      </m:math>
	    </caption>
	  </figure>
	    
	  If we plot the two densities so that each is weighted by its
	  <foreign>a priori</foreign> probability of occuring, the two
	  curves will intersect at the threshold
	  <m:math><m:ci>γ</m:ci></m:math> (see <link target-id="fig2"/>). (Can you explain why this is? Think back
	  to our derivation of the LRT). This plot also offers a way
	  to visualize the probability of error. Recall
	  <equation id="eqn3">
	  <m:math>
	    <m:apply>
	      <m:eq/>
	      <m:ci><m:msub>
		  <m:mi>P</m:mi>
		  <m:mi>e</m:mi>
		</m:msub></m:ci>
	      
	      <m:apply>
		<m:plus/>
		<m:apply>
		  <m:int/>
		  <m:bvar>
		    <m:ci>x</m:ci>
		  </m:bvar>
		  <m:domainofapplication>
		    <m:ci><m:msub>
			<m:mi>R</m:mi>
			<m:mn>0</m:mn>
		      </m:msub></m:ci>
		  </m:domainofapplication>
		  <m:apply>
		    <m:times/>
		    <m:ci><m:msub>
			<m:mi>π</m:mi>
			<m:mn>1</m:mn>
		      </m:msub></m:ci>
		    <m:apply>
		      <m:ci type="fn"><m:msub>
			  <m:mi>f</m:mi>
			  <m:mn>1</m:mn>
			</m:msub></m:ci>
		      <m:ci>x</m:ci>
		    </m:apply>
		  </m:apply>
		</m:apply>
		<m:apply>
		  <m:int/>
		  <m:bvar>
		    <m:ci>x</m:ci>
		  </m:bvar>
		  <m:domainofapplication>
		    <m:ci><m:msub>
			<m:mi>R</m:mi>
			<m:mn>1</m:mn>
		      </m:msub></m:ci>
		  </m:domainofapplication>
		  <m:apply>
		    <m:times/>
		    <m:ci><m:msub>
			<m:mi>π</m:mi>
			<m:mn>0</m:mn>
		      </m:msub></m:ci>
		    <m:apply>
		      <m:ci type="fn"><m:msub>
			  <m:mi>f</m:mi>
			  <m:mn>0</m:mn>
			</m:msub></m:ci>
		      <m:ci>x</m:ci>
		    </m:apply>
		  </m:apply>
		</m:apply>
	      </m:apply>
	      
	       <m:apply>
		<m:plus/>
		<m:apply>
		  <m:int/>
		  <m:bvar>
		    <m:ci>x</m:ci>
		  </m:bvar>
		  <m:domainofapplication>
		    <m:apply>
		      <m:lt/>
		      <m:ci>x</m:ci>
		      <m:ci>γ</m:ci>
		    </m:apply>
		  </m:domainofapplication>
		  <m:apply>
		    <m:times/>
		    <m:ci><m:msub>
			<m:mi>π</m:mi>
			<m:mn>1</m:mn>
		      </m:msub></m:ci>
		    <m:apply>
		      <m:ci type="fn"><m:msub>
			  <m:mi>f</m:mi>
			  <m:mn>1</m:mn>
			</m:msub></m:ci>
		      <m:ci>x</m:ci>
		    </m:apply>
		  </m:apply>
		</m:apply>
		<m:apply>
		  <m:int/>
		  <m:bvar>
		    <m:ci>x</m:ci>
		  </m:bvar>
		  <m:domainofapplication>
		    <m:apply>
		      <m:gt/>
		      <m:ci>x</m:ci>
		      <m:ci>γ</m:ci>
		    </m:apply>
		  </m:domainofapplication>
		  <m:apply>
		    <m:times/>
		    <m:ci><m:msub>
			<m:mi>π</m:mi>
			<m:mn>0</m:mn>
		      </m:msub></m:ci>
		    <m:apply>
		      <m:ci type="fn"><m:msub>
			  <m:mi>f</m:mi>
			  <m:mn>0</m:mn>
			</m:msub></m:ci>
		      <m:ci>x</m:ci>
		    </m:apply>
		  </m:apply>
		</m:apply>
	      </m:apply>

	      <m:apply>
		<m:plus/>
		<m:apply>
		  <m:times/>
		  <m:ci><m:msub>
		      <m:mi>π</m:mi>
		      <m:mn>1</m:mn>
		    </m:msub></m:ci>
		  <m:ci><m:msub>
		      <m:mi>P</m:mi>
		      <m:mi>M</m:mi>
		    </m:msub></m:ci>
		</m:apply>
		<m:apply>
		  <m:times/>
		  <m:ci><m:msub>
		      <m:mi>π</m:mi>
		      <m:mn>0</m:mn>
		    </m:msub></m:ci>
		  <m:ci><m:msub>
		      <m:mi>P</m:mi>
		      <m:mi>F</m:mi>
		    </m:msub></m:ci>
		</m:apply>
	      </m:apply>
	    </m:apply>
	  </m:math>
	  </equation>
	  where
	  <m:math>
	    <m:ci><m:msub>
		<m:mi>P</m:mi>
		<m:mi>M</m:mi>
	      </m:msub></m:ci>
	  </m:math>
	  and 
	  <m:math>
	    <m:ci><m:msub>
		<m:mi>P</m:mi>
		<m:mi>F</m:mi>
	      </m:msub></m:ci>
	  </m:math>
	  denote the miss and false alarm probabilities,
	  respectively. These quantities are depicted in <link target-id="fig2"/>.

	  <figure id="fig2">
	    <media id="idm249856" alt=""><image src="../../media/GaussUncMeanComVarPe.png" mime-type="image/png"/></media>
	    <caption>The candidate densities weighted by their
	    <foreign>a priori</foreign> probabilities. The shaded
	    region is the probability of error for the optimal
	    decision rule.
	    </caption>
	  </figure>
	  
	  We can express  
	  <m:math>
	    <m:ci><m:msub>
		<m:mi>P</m:mi>
		<m:mi>M</m:mi>
	      </m:msub></m:ci>
	  </m:math>
	  and 
	  <m:math>
	    <m:ci><m:msub>
		<m:mi>P</m:mi>
		<m:mi>F</m:mi>
	      </m:msub></m:ci>
	  </m:math>
	  in terms of the <link document="m11537">Q-function</link> as
	  <m:math display="block">
	    <m:apply>
	      <m:eq/>
	      <m:ci><m:msub>
		  <m:mi>P</m:mi>
		  <m:mi>e</m:mi>
		</m:msub></m:ci>
	      <m:apply>
		<m:plus/>
		<m:apply>
		  <m:times/>
		  <m:ci><m:msub>
		      <m:mi>π</m:mi>
		      <m:mn>1</m:mn>
		    </m:msub></m:ci>
		  <m:apply>
		    <m:ci type="fn">Q</m:ci>
		    <m:apply>
		      <m:divide/>
		      <m:apply>
			<m:minus/>
			<m:ci>μ</m:ci>
			<m:ci>γ</m:ci>
		      </m:apply>
		      <m:ci>σ</m:ci>
		    </m:apply>
		  </m:apply>
		</m:apply>
		<m:apply>
		  <m:times/>
		  <m:ci><m:msub>
		      <m:mi>π</m:mi>
		      <m:mn>0</m:mn>
		    </m:msub></m:ci>
		  <m:apply>
		    <m:ci type="fn">Q</m:ci>
		    <m:apply>
		      <m:divide/>
		      <m:ci>γ</m:ci>
		      <m:ci>σ</m:ci>
		    </m:apply>
		  </m:apply>
		</m:apply>
	      </m:apply>
	    </m:apply>
	  </m:math>
	  When 
	  <m:math>
	    <m:apply>
	      <m:eq/>
	      <m:ci><m:msub>
		  <m:mi>π</m:mi>
		  <m:mn>0</m:mn>
		</m:msub></m:ci>
	      <m:ci><m:msub>
		  <m:mi>π</m:mi>
		  <m:mn>1</m:mn>
		</m:msub></m:ci>
	      <m:apply>
		<m:divide/>
		<m:cn>1</m:cn>
		<m:cn>2</m:cn>
	      </m:apply>
	    </m:apply>
	  </m:math>, we have 
	  <m:math>
	    <m:apply>
	      <m:eq/>
	      <m:ci>γ</m:ci>
	      <m:apply>
		<m:divide/>
		<m:ci>μ</m:ci>
		<m:cn>2</m:cn>
	      </m:apply>
	    </m:apply>
	  </m:math>, and the error probability is
	  <m:math display="block">
	    <m:apply>
	      <m:eq/>
	      <m:ci><m:msub>
		  <m:mi>P</m:mi>
		  <m:mi>e</m:mi>
		</m:msub></m:ci>
	      <m:apply>
		<m:ci type="fn">Q</m:ci>
		<m:apply>
		  <m:divide/>
		  <m:ci>μ</m:ci>
		  <m:apply>
		    <m:times/>
		    <m:cn>2</m:cn>
		    <m:ci>σ</m:ci>
		  </m:apply>
		</m:apply>
	      </m:apply>
	    </m:apply>
	  </m:math>
	  Since
	  <m:math>
	    <m:apply>
	      <m:ci type="fn">Q</m:ci>
	      <m:ci>x</m:ci>
	    </m:apply>
	  </m:math> is monotonically decreasing, this says that the
	  "difficulty" of the detection problem decreases with
	  decreasing <m:math><m:ci>σ</m:ci></m:math> and
	  increasing <m:math><m:ci>μ</m:ci></m:math>.
	</para>
      </section>
    </example>

    <para id="para3">In the preceding example, computation of the
    probability of error involved a one-dimensional integral. If we
    had multiple observations, or vector-valued data, generalizing
    this procedure would involve multi-dimensional integrals over
    potentially complicated decision regions. Fortunately, in many
    cases, we can avoid this problem through the use of <link document="m11481">sufficient statistics</link>.
    </para>

    <example id="ex2">
      <para id="ex2para1">Suppose we have the same test as in the
      <link target-id="ex1">previous example</link>, but now we have
      <m:math><m:ci>N</m:ci></m:math> independent observations:
	<m:math display="block">
	  <m:mrow>
	    <m:msub>
	      <m:mi>ℋ</m:mi>
	      <m:mn>0</m:mn>
	    </m:msub>
	    <m:mo>:</m:mo>
	    <m:apply>
	      <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#distributedin"/>
	      <m:msub>
		<m:mi>x</m:mi>
		<m:mi>n</m:mi>
	      </m:msub>
	      <m:apply>
		<m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#normaldistribution"/>
		<m:mn>0</m:mn>
		<m:apply>
		  <m:power/>
		  <m:mi>σ</m:mi>
		  <m:mn>2</m:mn>
		</m:apply>
	      </m:apply>
	    </m:apply>
	    <m:mo>,</m:mo>
	    <m:mi>n</m:mi>
	    <m:mo>=</m:mo>
	    <m:mn>1</m:mn>
	    <m:mo>,</m:mo>
	    <m:mi>…</m:mi>
	    <m:mo>,</m:mo>
	    <m:mi>N</m:mi>
	  </m:mrow>
	</m:math>
	<m:math display="block">
	  <m:mrow>
	    <m:msub>
	      <m:mi>ℋ</m:mi>
	      <m:mn>1</m:mn>
	    </m:msub>
	    <m:mo>:</m:mo>
	    <m:apply>
	      <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#distributedin"/>
	      <m:msub>
		<m:mi>x</m:mi>
		<m:mi>n</m:mi>
	      </m:msub>
	      <m:apply>
		<m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#normaldistribution"/>
		<m:mi>μ</m:mi>
		<m:apply>
		  <m:power/>
		  <m:mi>σ</m:mi>
		  <m:mn>2</m:mn>
		</m:apply>
	      </m:apply>
	    </m:apply>
	    <m:mo>,</m:mo>
	    <m:mi>n</m:mi>
	    <m:mo>=</m:mo>
	    <m:mn>1</m:mn>
	    <m:mo>,</m:mo>
	    <m:mi>…</m:mi>
	    <m:mo>,</m:mo>
	    <m:mi>N</m:mi>
	  </m:mrow>
	</m:math>
	where
	<m:math>
	  <m:apply>
	    <m:gt/>
	    <m:ci>μ</m:ci>
	    <m:cn>0</m:cn>
	  </m:apply>
	</m:math> and
	<m:math>
	  <m:apply>
	    <m:gt/>
	    <m:apply>
	      <m:power/>
	      <m:ci>σ</m:ci>
	      <m:cn>2</m:cn>
	    </m:apply>
	    <m:cn>0</m:cn>
	  </m:apply>
	</m:math> and both are known. The likelihood ratio is
	<equation id="eqn4">
	<m:math>
	  <m:apply>
	    <m:eq/>
	    <m:apply>
	      <m:ci type="fn">Λ</m:ci>
	      <m:ci type="vector">x</m:ci>
	    </m:apply>

	    <m:apply>
	      <m:divide/>
	      <m:apply>
		<m:product/>
		<m:bvar>
		  <m:ci>n</m:ci>
		</m:bvar>
		<m:lowlimit>
		  <m:cn>1</m:cn>
		</m:lowlimit>
		<m:uplimit>
		  <m:ci>N</m:ci>
		</m:uplimit>
		<m:apply>
		  <m:times/>
		  <m:apply>
		    <m:divide/>
		    <m:cn>1</m:cn>
		    <m:apply>
		      <m:root/>
		      <m:apply>
			<m:times/>
			<m:cn>2</m:cn>
			<m:pi/>
			<m:apply>
			  <m:power/>
			  <m:ci>σ</m:ci>
			  <m:cn>2</m:cn>
			</m:apply>
		      </m:apply>
		    </m:apply>
		  </m:apply>
		  <m:apply>
		    <m:exp/>
		    <m:apply>
		      <m:minus/>
		      <m:apply>
			<m:divide/>
			<m:apply>
			  <m:power/>
			  <m:apply>
			    <m:minus/>
			    <m:ci><m:msub>
				<m:mi>x</m:mi>
				<m:mi>n</m:mi>			      
			      </m:msub></m:ci>
			    <m:ci>μ</m:ci>
			  </m:apply>
			  <m:cn>2</m:cn>
			</m:apply>
			<m:apply>
			  <m:times/>
			  <m:cn>2</m:cn>
			  <m:apply>
			    <m:power/>
			    <m:ci>σ</m:ci>
			    <m:cn>2</m:cn>
			  </m:apply>
			</m:apply>
		      </m:apply>
		    </m:apply>
		  </m:apply>
		</m:apply>
	      </m:apply>
	      <m:apply>
		<m:product/>
		<m:bvar>
		  <m:ci>n</m:ci>
		</m:bvar>
		<m:lowlimit>
		  <m:cn>1</m:cn>
		</m:lowlimit>
		<m:uplimit>
		  <m:ci>N</m:ci>
		</m:uplimit>
		<m:apply>
		  <m:times/>
		  <m:apply>
		    <m:divide/>
		    <m:cn>1</m:cn>
		    <m:apply>
		      <m:root/>
		      <m:apply>
			<m:times/>
			<m:cn>2</m:cn>
			<m:pi/>
			<m:apply>
			  <m:power/>
			  <m:ci>σ</m:ci>
			  <m:cn>2</m:cn>
			</m:apply>
		      </m:apply>
		    </m:apply>
		  </m:apply>
		  <m:apply>
		    <m:exp/>
		    <m:apply>
		      <m:minus/>
		      <m:apply>
			<m:divide/>
			<m:apply>
			  <m:power/>
			  <m:ci><m:msub>
			      <m:mi>x</m:mi>
			      <m:mi>n</m:mi>			      
			    </m:msub></m:ci>
			  <m:cn>2</m:cn>
			</m:apply>
			<m:apply>
			  <m:times/>
			  <m:cn>2</m:cn>
			  <m:apply>
			    <m:power/>
			    <m:ci>σ</m:ci>
			    <m:cn>2</m:cn>
			  </m:apply>
			</m:apply>
		      </m:apply>
		    </m:apply>
		  </m:apply>
		</m:apply>
	      </m:apply>
	    </m:apply>

	    <m:apply>
	      <m:divide/>
	      <m:apply>
		<m:exp/>
		<m:apply>
		  <m:times/>
		  <m:apply>
		    <m:divide/>
		    <m:cn>-1</m:cn>
		    <m:apply>
		      <m:times/>
		      <m:cn>2</m:cn>
		      <m:apply>
			<m:power/>
			<m:ci>σ</m:ci>
			<m:cn>2</m:cn>
		      </m:apply>
		    </m:apply>
		  </m:apply>
		  <m:apply>
		    <m:sum/>
		    <m:bvar>
		      <m:ci>n</m:ci>
		    </m:bvar>
		    <m:lowlimit>
		      <m:cn>1</m:cn>
		    </m:lowlimit>
		    <m:uplimit>
		      <m:ci>N</m:ci>
		    </m:uplimit>
		    <m:apply>
		      <m:power/>
		      <m:apply>
			<m:minus/>
			<m:ci><m:msub>
			    <m:mi>x</m:mi>
			    <m:mi>n</m:mi>			      
			  </m:msub></m:ci>
			<m:ci>μ</m:ci>
		      </m:apply>
		      <m:cn>2</m:cn>
		    </m:apply>
		  </m:apply>
		</m:apply>
	      </m:apply>
	      <m:apply>
		<m:exp/>
		<m:apply>
		  <m:times/>
		  <m:apply>
		    <m:divide/>
		    <m:cn>-1</m:cn>
		    <m:apply>
		      <m:times/>
		      <m:cn>2</m:cn>
		      <m:apply>
			<m:power/>
			<m:ci>σ</m:ci>
			<m:cn>2</m:cn>
		      </m:apply>
		    </m:apply>
		  </m:apply>
		  <m:apply>
		    <m:sum/>
		    <m:bvar>
		      <m:ci>n</m:ci>
		    </m:bvar>
		    <m:lowlimit>
		      <m:cn>1</m:cn>
		    </m:lowlimit>
		    <m:uplimit>
		      <m:ci>N</m:ci>
		    </m:uplimit>
		    <m:apply>
		      <m:power/>
		      <m:ci><m:msub>
			  <m:mi>x</m:mi>
			  <m:mi>n</m:mi>			      
			</m:msub></m:ci>
		      <m:cn>2</m:cn>
		    </m:apply>
		  </m:apply>
		</m:apply>
	      </m:apply>
	    </m:apply>

	    <m:apply>
	      <m:exp/>
	      <m:apply>
		<m:times/>
		<m:apply>
		  <m:divide/>
		  <m:cn>1</m:cn>
		  <m:apply>
		    <m:times/>
		    <m:cn>2</m:cn>
		    <m:apply>
		      <m:power/>
		      <m:ci>σ</m:ci>
		      <m:cn>2</m:cn>
		    </m:apply>
		  </m:apply>
		</m:apply>
		<m:apply>
		  <m:sum/>
		  <m:bvar>
		    <m:ci>n</m:ci>
		  </m:bvar>
		  <m:lowlimit>
		    <m:cn>1</m:cn>
		  </m:lowlimit>
		  <m:uplimit>
		    <m:ci>N</m:ci>
		  </m:uplimit>
		  <m:apply>
		    <m:minus/>
		    <m:apply>
		      <m:times/>
		      <m:cn>2</m:cn>
		      <m:ci><m:msub>
			  <m:mi>x</m:mi>
			  <m:mi>n</m:mi>
			</m:msub></m:ci>
		      <m:ci>μ</m:ci>
		    </m:apply>
		    <m:apply>
		      <m:power/>
		      <m:ci>μ</m:ci>
		      <m:cn>2</m:cn>
		    </m:apply>
		  </m:apply>
		</m:apply>
	      </m:apply>
	    </m:apply>
	  
	    <m:apply>
	      <m:exp/>
	      <m:apply>
		<m:times/>
		<m:apply>
		  <m:divide/>
		  <m:cn>1</m:cn>
		  <m:apply>
		    <m:power/>
		    <m:ci>σ</m:ci>
		    <m:cn>2</m:cn>
		  </m:apply>
		</m:apply>
		<m:apply>
		  <m:minus/>
		  <m:apply>
		    <m:times/>
		    <m:ci>μ</m:ci>
		    <m:apply>
		      <m:sum/>
		      <m:bvar>
			<m:ci>n</m:ci>
		      </m:bvar>
		      <m:lowlimit>
			<m:cn>1</m:cn>
		      </m:lowlimit>
		      <m:uplimit>
			<m:ci>N</m:ci>
		      </m:uplimit>
		      <m:ci><m:msub>
			  <m:mi>x</m:mi>
			  <m:mi>n</m:mi>
			</m:msub></m:ci>
		    </m:apply>
		  </m:apply>
		  <m:apply>
		    <m:divide/>
		    <m:apply>
		      <m:times/>
		      <m:ci>N</m:ci>
		      <m:apply>
			<m:power/>
			<m:ci>μ</m:ci>
			<m:cn>2</m:cn>
		      </m:apply>
		    </m:apply>
		    <m:cn>2</m:cn>
		  </m:apply>
		</m:apply>
	      </m:apply>
	    </m:apply>
	  </m:apply>
	</m:math>
	</equation>
	As in the <link target-id="ex1">previous example</link>,
	we may apply the natural logarithm and rearrange terms to
	obtain an equivalent form of the LRT:
	<m:math display="block">
	  <m:mrow>
	    <m:apply>
	      <m:equivalent/>
	      <m:mi>t</m:mi>
	      <m:apply>
		<m:sum/>
		<m:bvar>
		  <m:ci>n</m:ci>
		</m:bvar>
		<m:lowlimit>
		  <m:cn>1</m:cn>
		</m:lowlimit>
		<m:uplimit>
		  <m:ci>N</m:ci>
		</m:uplimit>
		<m:ci><m:msub>
		    <m:mi>x</m:mi>
		    <m:mi>n</m:mi>
		  </m:msub></m:ci>
	      </m:apply>
	    </m:apply>

	    <m:munderover>
	      <m:mo>≷</m:mo>
	      <m:msub>
		<m:mi>ℋ</m:mi>
		<m:mn>0</m:mn>
	      </m:msub>
	      <m:msub>
		<m:mi>ℋ</m:mi>
		<m:mn>1</m:mn>
	      </m:msub>
	    </m:munderover>

	    <m:apply>
	      <m:equivalent/>
	      <m:apply>
		<m:plus/>
		<m:apply>
		  <m:times/>
		  <m:apply>
		    <m:divide/>
		    <m:apply>
		      <m:power/>
		      <m:mi>σ</m:mi>
		      <m:mn>2</m:mn>
		    </m:apply>
		    <m:mi>μ</m:mi>
		  </m:apply>
		  <m:apply>
		    <m:ln/>
		    <m:mi>η</m:mi>
		  </m:apply>
		</m:apply>
		<m:apply>
		  <m:divide/>
		  <m:apply>
		    <m:times/>
		    <m:mi>N</m:mi>
		    <m:mi>μ</m:mi>
		  </m:apply>
		  <m:mn>2</m:mn>
		</m:apply>
	      </m:apply>
	      <m:mi>γ</m:mi>
	    </m:apply>
	  </m:mrow>
	</m:math>
	The scalar quantity <m:math><m:ci>t</m:ci></m:math> is a
	sufficient statistic for the mean. In order to evaluate the
	probability of error without resorting to a multi-dimensional
	integral, we can express
	<m:math>
	  <m:ci><m:msub>
	      <m:mi>P</m:mi>
	      <m:mi>e</m:mi>
	    </m:msub></m:ci>
	</m:math> in terms of <m:math><m:ci>t</m:ci></m:math> as
	<m:math display="block">
	  <m:apply>
	    <m:eq/>
	    <m:ci><m:msub>
		<m:mi>P</m:mi>
		<m:mi>e</m:mi>
	      </m:msub></m:ci>
	    <m:apply>
	      <m:plus/>
	      <m:apply>
		<m:times/>
		<m:ci><m:msub>
		    <m:mi>π</m:mi>
		    <m:mn>1</m:mn>
		  </m:msub></m:ci>
		<m:apply>
		  <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#probability"/>
		  <m:condition>
		    <m:mrow>
		      <m:msub>
			<m:mi>ℋ</m:mi>
			<m:mn>1</m:mn>
		      </m:msub>
		      <m:mtext> true</m:mtext>
		    </m:mrow>
		  </m:condition>
		  <m:apply>
		    <m:lt/>
		    <m:ci>t</m:ci>
		    <m:ci>γ</m:ci>
		  </m:apply>
		</m:apply>
	      </m:apply>
	      <m:apply>
		<m:times/>
		<m:ci><m:msub>
		    <m:mi>π</m:mi>
		    <m:mn>0</m:mn>
		  </m:msub></m:ci>
		<m:apply>
		  <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#probability"/>
		  <m:condition>
		    <m:mrow>
		      <m:msub>
			<m:mi>ℋ</m:mi>
			<m:mn>0</m:mn>
		      </m:msub>
		      <m:mtext> true</m:mtext>
		    </m:mrow>
		  </m:condition>
		  <m:apply>
		    <m:gt/>
		    <m:ci>t</m:ci>
		    <m:ci>γ</m:ci>
		  </m:apply>
		</m:apply>
	      </m:apply>
	    </m:apply>
	  </m:apply>
	</m:math>
	Now <m:math><m:ci>t</m:ci></m:math> is a linear combination of
	normal variates, so it is itself normal. In particular, we
	have
	<m:math>
	  <m:apply>
	    <m:eq/>
	    <m:ci>t</m:ci>
	    <m:apply>
	      <m:times/>
	      <m:ci type="vector">A</m:ci>
	      <m:ci type="vector">x</m:ci>
	    </m:apply>
	  </m:apply>
	</m:math>, where
	<m:math>
	  <m:matrix>
	    <m:matrixrow>
	      <m:cn>1</m:cn>
	      <m:ci>…</m:ci>
	      <m:cn>1</m:cn>
	    </m:matrixrow>
	  </m:matrix>
	</m:math> is an <m:math><m:ci>N</m:ci></m:math>-dimensional
	row vector of 1's, and <m:math><m:ci type="vector">x</m:ci></m:math> is multivariate normal with
	mean <m:math><m:ci type="vector">0</m:ci></m:math> or
	<m:math display="inline">
	  <m:apply>
	    <m:eq/>
	    <m:ci type="vector">μ</m:ci>
	    <m:vector>
	      <m:ci>μ</m:ci>
	      <m:ci>…</m:ci>
	      <m:ci>μ</m:ci>
	    </m:vector>
	  </m:apply>
	</m:math>, and covariance
	<m:math>
	  <m:apply>
	    <m:times/>
	    <m:apply>
	      <m:power/>
	      <m:ci>σ</m:ci>
	      <m:cn>2</m:cn>
	    </m:apply>
	    <m:ci type="matrix">I</m:ci>
	  </m:apply>
	</m:math>. Thus we have
	
	<m:math display="block">
	  <m:apply>
	    <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#distributedin"/>
	    <m:mrow>
	      <m:mi>t</m:mi>
	      <m:mo>|</m:mo>
	      <m:msub>
		<m:mi>ℋ</m:mi>
		<m:mn>0</m:mn>
	      </m:msub>
	    </m:mrow>
	    <m:apply>
	      <m:eq/>
	      <m:apply>
		<m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#normaldistribution"/>
		<m:apply>
		  <m:times/>
		  <m:ci type="vector">A</m:ci>
		  <m:ci type="vector">0</m:ci>
		</m:apply>
		<m:apply>
		  <m:times/>
		  <m:ci type="vector">A</m:ci>
		  <m:apply>
		    <m:power/>
		    <m:ci>σ</m:ci>
		    <m:cn>2</m:cn>
		  </m:apply>
		  <m:ci type="matrix">I</m:ci>
		  <m:apply>
		    <m:transpose/>
		    <m:ci type="vector">A</m:ci>
		  </m:apply>
		</m:apply>
	      </m:apply>
	      <m:apply>
		<m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#normaldistribution"/>
		<m:cn>0</m:cn>
		<m:apply>
		  <m:times/>
		  <m:ci>N</m:ci>
		  <m:apply>
		    <m:power/>
		    <m:ci>σ</m:ci>
		    <m:cn>2</m:cn>
		  </m:apply>
		</m:apply>
	      </m:apply>
	    </m:apply>
	  </m:apply>
	</m:math>

	<m:math display="block">
	  <m:apply>
	    <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#distributedin"/>
	    <m:mrow>
	      <m:mi>t</m:mi>
	      <m:mo>|</m:mo>
	      <m:msub>
		<m:mi>ℋ</m:mi>
		<m:mn>1</m:mn>
	      </m:msub>
	    </m:mrow>
	    <m:apply>
	      <m:eq/>
	      <m:apply>
		<m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#normaldistribution"/>
		<m:apply>
		  <m:times/>
		  <m:ci type="vector">A</m:ci>
		  <m:ci type="vector">μ</m:ci>
		</m:apply>
		<m:apply>
		  <m:times/>
		  <m:ci type="vector">A</m:ci>
		  <m:apply>
		    <m:power/>
		    <m:ci>σ</m:ci>
		    <m:cn>2</m:cn>
		  </m:apply>
		  <m:ci type="matrix">I</m:ci>
		  <m:apply>
		    <m:transpose/>
		    <m:ci type="vector">A</m:ci>
		  </m:apply>
		</m:apply>
	      </m:apply>
	      <m:apply>
		<m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#normaldistribution"/>
		<m:apply>
		  <m:times/>
		  <m:ci>N</m:ci>
		  <m:ci>μ</m:ci>
		</m:apply>
		<m:apply>
		  <m:times/>
		  <m:ci>N</m:ci>
		  <m:apply>
		    <m:power/>
		    <m:ci>σ</m:ci>
		    <m:cn>2</m:cn>
		  </m:apply>
		</m:apply>
	      </m:apply>
	    </m:apply>
	  </m:apply>
	</m:math>

	Therefore, we may write 
	<m:math>
	  <m:ci><m:msub>
	      <m:mi>P</m:mi>
	      <m:mi>e</m:mi>
	    </m:msub></m:ci>
	</m:math>
	in terms of the <link document="m11537">Q-function</link> as
	<m:math display="block">
	  <m:apply>
	    <m:eq/>
	    <m:ci><m:msub>
		<m:mi>P</m:mi>
		<m:mi>e</m:mi>
	      </m:msub></m:ci>
	    <m:apply>
	      <m:plus/>
	      <m:apply>
		<m:times/>
		<m:ci><m:msub>
		    <m:mi>π</m:mi>
		    <m:mn>1</m:mn>
		  </m:msub></m:ci>
		<m:apply>
		  <m:ci type="fn">Q</m:ci>
		  <m:apply>
		    <m:divide/>
		    <m:apply>
		      <m:minus/>
		      <m:apply>
			<m:times/>
			<m:ci>N</m:ci>
			<m:ci>μ</m:ci>
		      </m:apply>
		      <m:ci>γ</m:ci>
		    </m:apply>
		    <m:apply>
		      <m:times/>
		      <m:apply>
			<m:root/>
			<m:ci>N</m:ci>
		      </m:apply>
		      <m:ci>σ</m:ci>
		    </m:apply>
		  </m:apply>
		</m:apply>
	      </m:apply>
	      <m:apply>
		<m:times/>
		<m:ci><m:msub>
		    <m:mi>π</m:mi>
		    <m:mn>0</m:mn>
		  </m:msub></m:ci>
		<m:apply>
		  <m:ci type="fn">Q</m:ci>
		  <m:apply>
		    <m:divide/>
		    <m:ci>γ</m:ci>
		    <m:apply>
		      <m:times/>
		      <m:apply>
			<m:root/>
			<m:ci>N</m:ci>
		      </m:apply>
		      <m:ci>σ</m:ci>
		    </m:apply>
		  </m:apply>
		</m:apply>
	      </m:apply>
	    </m:apply>
	  </m:apply>
	</m:math>
     
	In the special case
	<m:math>
	  <m:apply>
	    <m:eq/>
	    <m:ci><m:msub>
		<m:mi>π</m:mi>
		<m:mn>0</m:mn>
	      </m:msub></m:ci>
	    <m:ci><m:msub>
		<m:mi>π</m:mi>
		<m:mn>1</m:mn>
	      </m:msub></m:ci>
	    <m:apply>
	      <m:divide/>
	      <m:cn>1</m:cn>
	      <m:cn>2</m:cn>
	    </m:apply>
	  </m:apply>
	</m:math>, 
	<m:math display="block">
	  <m:apply>
	    <m:eq/>
	    <m:ci><m:msub>
		<m:mi>P</m:mi>
		<m:mi>e</m:mi>
	      </m:msub></m:ci>
	    <m:apply>
	      <m:ci type="fn">Q</m:ci>
	      <m:apply>
		<m:divide/>
		<m:apply>
		  <m:times/>
		  <m:apply>
		    <m:root/>
		    <m:ci>N</m:ci>
		  </m:apply>
		  <m:ci>μ</m:ci>
		</m:apply>
		<m:ci>σ</m:ci>
	      </m:apply>
	    </m:apply>
	  </m:apply>
	</m:math>
	Since <m:math><m:ci type="fn">Q</m:ci></m:math> is monotonically
	decreasing, this result provides mathematical support for
	something that is intuitively obvious: The performance of our
	decision rule improves with increasing
	<m:math><m:ci>N</m:ci></m:math> and
	<m:math><m:ci>μ</m:ci></m:math>, and decreasing
	<m:math><m:ci>σ</m:ci></m:math>.
	
	<!-- Note for future: Insert applet that plots P_e as a
	function of these unknown parameters -->

	<!-- FIXME, missing module so bad connexion -->
	<note type="remark" id="idm6226272"><label>Remark</label>In the context of signal processing, the
	foregoing problem may be viewed as the problem of detecting a
	constant (DC) signal in <link document="">additive white
	Gaussian noise</link>:

	  <m:math display="block">
	    
	    <m:mrow>
	      <m:msub>
		<m:mi>ℋ</m:mi>
		<m:mn>0</m:mn>
	      </m:msub>
	      <m:mo>:</m:mo>
	      <m:apply>
		<m:eq/>
		<m:msub>
		  <m:mi>x</m:mi>
		  <m:mi>n</m:mi>
		</m:msub>
		<m:msub>
		  <m:mi>w</m:mi>
		  <m:mi>n</m:mi>
		</m:msub>
	      </m:apply>
	      <m:mo>,</m:mo>
	      <m:mi>n</m:mi>
	      <m:mo>=</m:mo>
	      <m:mn>1</m:mn>
	      <m:mo>,</m:mo>
	      <m:mi>…</m:mi>
	      <m:mo>,</m:mo>
	      <m:mi>N</m:mi>
	    </m:mrow>
	 
	  </m:math>

	  <m:math display="block">
	   
	    <m:mrow>
	      <m:msub>
		<m:mi>ℋ</m:mi>
		<m:mn>1</m:mn>
	      </m:msub>
	      <m:mo>:</m:mo>
	      <m:apply>
		<m:eq/>
		<m:msub>
		  <m:mi>x</m:mi>
		  <m:mi>n</m:mi>
		</m:msub>
		<m:apply>
		  <m:plus/>
		  <m:mi>A</m:mi>
		  <m:msub>
		    <m:mi>w</m:mi>
		    <m:mi>n</m:mi>
		  </m:msub>
		</m:apply>
	      </m:apply>
	      <m:mo>,</m:mo>
	      <m:mi>n</m:mi>
	      <m:mo>=</m:mo>
	      <m:mn>1</m:mn>
	      <m:mo>,</m:mo>
	      <m:mi>…</m:mi>
	      <m:mo>,</m:mo>
	      <m:mi>N</m:mi>
	    </m:mrow>
	   
	  </m:math>

	  where <m:math><m:ci>A</m:ci></m:math> is a known, fixed
	  amplitude, and
	  <m:math>
	    <m:apply>
	      <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#distributedin"/>
	      <m:ci><m:msub>
		  <m:mi>w</m:mi>
		  <m:mi>n</m:mi>
		</m:msub></m:ci>
	      <m:apply>
		<m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#normaldistribution"/>
		<m:cn>0</m:cn>
		<m:apply>
		  <m:power/>
		  <m:ci>σ</m:ci>
		  <m:cn>2</m:cn>
		</m:apply>
	      </m:apply>
	    </m:apply>
	  </m:math>. Here <m:math><m:ci>A</m:ci></m:math> corresponds
	  to the mean <m:math><m:ci>μ</m:ci></m:math> in the
	  example.
	</note>
      </para>
    </example>

    <para id="parashort">The next example explores the minimum
    probability of error decision rule in a
    <emphasis>discrete</emphasis> setting.
    </para>

    <example id="ex3">
      <section id="rc">
	<title>Repetition Code</title>

	<para id="rc1">Suppose we have a friend who is trying to
	transmit a bit (0 or 1) to us over a noisy channel. The
	channel causes an error in the transmission (that is, the bit
	is flipped) with probability <m:math><m:ci>p</m:ci></m:math>,
	where
	  <m:math>
	    <m:apply>
	      <m:lt/>
	      <m:apply>
		<m:leq/>
		<m:cn>0</m:cn>
		<m:ci>p</m:ci>
	      </m:apply>
	      <m:apply>
		<m:divide/>
		<m:cn>1</m:cn>
		<m:cn>2</m:cn>
	      </m:apply>
	    </m:apply>
	  </m:math>, and <m:math><m:ci>p</m:ci></m:math> is known. In
	  order to increase the chance of a successful transmission,
	  our friend sends the same bit
	  <m:math><m:ci>N</m:ci></m:math> times. Assume the
	  <m:math><m:ci>N</m:ci></m:math> transmissions are
	  statistically independent. Under these assumptions, the bits
	  you receive are Bernoulli random variables:
	  <m:math>
	    <m:apply>
	      <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#distributedin"/>
	      <m:ci><m:msub>
		  <m:mi>x</m:mi>
		  <m:mi>n</m:mi>
		</m:msub></m:ci>
	      <m:apply>
		<m:ci type="fn">Bernoulli</m:ci>
		<m:ci>θ</m:ci>
	      </m:apply>
	    </m:apply>
	  </m:math>. We are faced with the following hypothesis test:
	  <table frame="all" id="table1" summary="">
	    <tgroup cols="3" align="center" colsep="1" rowsep="1">
	      <tbody>
		<row>
		  <entry>
		    <m:math>
		      <m:msub>
			<m:mi>ℋ</m:mi>
			<m:mn>0</m:mn>
		      </m:msub>
		    </m:math>
		  </entry>
		  <entry> 
		    <m:math>
		      <m:apply>
			<m:eq/>
			<m:mi>θ</m:mi>
			<m:mi>p</m:mi>
		      </m:apply>
		    </m:math>
		  </entry>
		  <entry>0 sent</entry>
		</row>
		<row>
		  <entry>
		    <m:math>
		      <m:msub>
			<m:mi>ℋ</m:mi>
			<m:mn>1</m:mn>
		      </m:msub>
		    </m:math>
		  </entry>
		  <entry> 
		    <m:math>
		      <m:apply>
			<m:eq/>
			<m:mi>θ</m:mi>
			<m:apply>
			  <m:minus/>
			  <m:cn>1</m:cn>
			  <m:mi>p</m:mi>
			</m:apply>
		      </m:apply>
		    </m:math>
		  </entry>
		  <entry>1 sent</entry>
		</row>
	      </tbody>
	    </tgroup>
	  </table>
		
	  We decide to decode the received sequence
	  <m:math display="inline">
	    <m:apply>
	      <m:eq/>
	      <m:ci type="vector">x</m:ci>
	      <m:vector>
		<m:ci><m:msub>
		    <m:mi>x</m:mi>
		    <m:mn>1</m:mn>
		  </m:msub></m:ci>
		<m:ci>…</m:ci>
		<m:ci><m:msub>
		    <m:mi>x</m:mi>
		    <m:mi>N</m:mi>
		  </m:msub></m:ci>
	      </m:vector>
	    </m:apply>
	  </m:math>
	  by minimizing the probability of error. The likelihood ratio is
	  <equation id="eqn5">
	  <m:math>
	    <m:apply>
	      <m:eq/>
	      <m:apply>
		<m:ci type="fn">Λ</m:ci>
		<m:ci type="vector">x</m:ci>
	      </m:apply>
	      <m:apply>
		<m:divide/>
		<m:apply>
		  <m:product/>
		  <m:bvar>
		    <m:ci>n</m:ci>
		  </m:bvar>
		  <m:lowlimit>
		    <m:cn>1</m:cn>
		  </m:lowlimit>
		  <m:uplimit>
		    <m:ci>N</m:ci>
		  </m:uplimit>
		  <m:apply>
		    <m:times/>
		    <m:apply>
		      <m:power/>
		      <m:apply>
			<m:minus/>
			<m:cn>1</m:cn>
			<m:ci>p</m:ci>
		      </m:apply>
		      <m:ci><m:msub>
			  <m:mi>x</m:mi>
			  <m:mi>n</m:mi>
			</m:msub></m:ci>
		    </m:apply>
		    <m:apply>
		      <m:power/>
		      <m:ci>p</m:ci>
		      <m:apply>
			<m:minus/>
			<m:cn>1</m:cn>
			<m:ci><m:msub>
			    <m:mi>x</m:mi>
			    <m:mi>n</m:mi>
			  </m:msub></m:ci>
		      </m:apply>
		    </m:apply>
		  </m:apply>
		</m:apply>
		<m:apply>
		  <m:product/>
		  <m:bvar>
		    <m:ci>n</m:ci>
		  </m:bvar>
		  <m:lowlimit>
		    <m:cn>1</m:cn>
		  </m:lowlimit>
		  <m:uplimit>
		    <m:ci>N</m:ci>
		  </m:uplimit>
		  <m:apply>
		    <m:times/>
		    <m:apply>
		      <m:power/>
		      <m:ci>p</m:ci>
		      <m:ci><m:msub>
			  <m:mi>x</m:mi>
			  <m:mi>n</m:mi>
			</m:msub></m:ci>
		    </m:apply>
		    <m:apply>
		      <m:power/>
		      <m:apply>
			<m:minus/>
			<m:cn>1</m:cn>
			<m:ci>p</m:ci>
		      </m:apply>
		      <m:apply>
			<m:minus/>
			<m:cn>1</m:cn>
			<m:ci><m:msub>
			    <m:mi>x</m:mi>
			    <m:mi>n</m:mi>
			  </m:msub></m:ci>
		      </m:apply>
		    </m:apply>
		  </m:apply>
		</m:apply>
	      </m:apply>

	      <m:apply>
		<m:divide/>
		<m:apply>
		  <m:times/>
		  <m:apply>
		    <m:power/>
		    <m:apply>
		      <m:minus/>
		      <m:cn>1</m:cn>
		      <m:ci>p</m:ci>
		    </m:apply>
		    <m:ci>k</m:ci>
		  </m:apply>
		  <m:apply>
		    <m:power/>
		    <m:ci>p</m:ci>
		    <m:apply>
		      <m:minus/>
		      <m:ci>N</m:ci>
		      <m:ci>k</m:ci>
		    </m:apply>
		  </m:apply>
		</m:apply>
		<m:apply>
		  <m:times/>
		  <m:apply>
		    <m:power/>
		    <m:ci>p</m:ci>
		    <m:ci>k</m:ci>
		  </m:apply>
		  <m:apply>
		    <m:power/>
		    <m:apply>
		      <m:minus/>
		      <m:cn>1</m:cn>
		      <m:ci>p</m:ci>
		    </m:apply>
		    <m:apply>
		      <m:minus/>
		      <m:ci>N</m:ci>
		      <m:ci>k</m:ci>
		    </m:apply>
		  </m:apply>
		</m:apply>
	      </m:apply>

	      <m:apply>
		<m:power/>
		<m:apply>
		  <m:divide/>
		  <m:apply>
		    <m:minus/>
		    <m:cn>1</m:cn>
		    <m:ci>p</m:ci>
		  </m:apply>
		  <m:ci>p</m:ci>
		</m:apply>
		<m:apply>
		  <m:minus/>
		  <m:apply>
		    <m:times/>
		    <m:cn>2</m:cn>
		    <m:ci>k</m:ci>
		  </m:apply>
		  <m:ci>N</m:ci>
		</m:apply>
	      </m:apply>
	    </m:apply>
	  </m:math>
	  </equation>
	  where
	  <m:math>
	    <m:apply>
	      <m:eq/>
	      <m:ci>k</m:ci>
	      <m:apply>
		<m:sum/>
		<m:bvar>
		  <m:ci>n</m:ci>
		</m:bvar>
		<m:lowlimit>
		  <m:cn>1</m:cn>
		</m:lowlimit>
		<m:uplimit>
		  <m:ci>N</m:ci>
		</m:uplimit>
		<m:ci><m:msub>
		    <m:mi>x</m:mi>
		    <m:mi>n</m:mi>
		  </m:msub></m:ci>
	      </m:apply>
	    </m:apply>
	  </m:math> is the number of 1s received.
	  <note id="idm6513184"><m:math><m:ci>k</m:ci></m:math> is a <link document="m11481">sufficient statistic</link> for
	  <m:math><m:ci>θ</m:ci></m:math>.</note>
	  The LRT is
	  <m:math display="block">
	    <m:mrow>
	      <m:apply>
		<m:power/>
		<m:apply>
		  <m:divide/>
		  <m:apply>
		    <m:minus/>
		    <m:mn>1</m:mn>
		    <m:mi>p</m:mi>
		  </m:apply>
		  <m:mi>p</m:mi>
		</m:apply>
		<m:apply>
		  <m:minus/>
		  <m:apply>
		    <m:times/>
		    <m:mn>2</m:mn>
		    <m:mi>k</m:mi>
		  </m:apply>
		  <m:mi>N</m:mi>
		</m:apply>
	      </m:apply>

	      <m:munderover>
		<m:mo>≷</m:mo>
		<m:msub>
		  <m:mi>ℋ</m:mi>
		  <m:mn>0</m:mn>
		</m:msub>
		<m:msub>
		  <m:mi>ℋ</m:mi>
		  <m:mn>1</m:mn>
		</m:msub>
	      </m:munderover>

	      <m:apply>
		<m:eq/>
		<m:apply>
		  <m:divide/>
		  <m:ci><m:msub>
		      <m:mi>π</m:mi>
		      <m:mn>0</m:mn>
		    </m:msub></m:ci>
		  <m:ci><m:msub>
		      <m:mi>π</m:mi>
		      <m:mn>1</m:mn>
		    </m:msub></m:ci>
		</m:apply>
		<m:mi>η</m:mi>
	      </m:apply>
	    </m:mrow>
	  </m:math>
	  Taking the natural logarithm of both sides and rearranging,
	  we have

	  <m:math display="block">
	    <m:mrow>
	      <m:mi>k</m:mi>

	      <m:munderover>
		<m:mo>≷</m:mo>
		<m:msub>
		  <m:mi>ℋ</m:mi>
		  <m:mn>0</m:mn>
		</m:msub>
		<m:msub>
		  <m:mi>ℋ</m:mi>
		  <m:mn>1</m:mn>
		</m:msub>
	      </m:munderover>

	      <m:apply>
		<m:eq/>
		<m:apply>
		  <m:plus/>
		  <m:apply>
		    <m:divide/>
		    <m:mi>N</m:mi>
		    <m:mn>2</m:mn>
		  </m:apply>
		  <m:apply>
		    <m:times/>
		    <m:apply>
		      <m:divide/>
		      <m:mn>1</m:mn>
		      <m:mn>2</m:mn>
		    </m:apply>
		    <m:apply>
		      <m:divide/>
		      <m:apply>
			<m:ln/>
			<m:mi>η</m:mi>
		      </m:apply>
		      <m:apply>
			<m:ln/>
			<m:apply>
			  <m:divide/>
			  <m:apply>
			    <m:minus/>
			    <m:mn>1</m:mn>
			    <m:mi>p</m:mi>
			  </m:apply>
			  <m:mi>p</m:mi>
			</m:apply>
		      </m:apply>
		    </m:apply>
		  </m:apply>
		</m:apply>
		<m:mi>γ</m:mi>
	      </m:apply>
	    </m:mrow>
	  </m:math>
	  In the case that both hypotheses are equally likely, the
	  minimum probability of error decision is the "majority-vote"
	  rule: Declare
	  <m:math>
	    <m:ci><m:msub>
		<m:mi>ℋ</m:mi>
		<m:mn>1</m:mn>
	      </m:msub></m:ci>
	  </m:math> if there are more 1s than 0s, declare
	  <m:math>
	    <m:ci><m:msub>
		<m:mi>ℋ</m:mi>
		<m:mn>0</m:mn>
	      </m:msub></m:ci>
	  </m:math> otherwise. In the event
	  <m:math>
	    <m:apply>
	      <m:eq/>
	      <m:ci>k</m:ci>
	      <m:ci>γ</m:ci>
	    </m:apply>
	  </m:math>, we may decide arbitrarily; the probability of
	  error is the same either way. Let's adopt the convention
	  that
	  <m:math>
	    <m:ci><m:msub>
		<m:mi>ℋ</m:mi>
		<m:mn>0</m:mn>
	      </m:msub></m:ci>
	  </m:math> is declared in this case.
	</para>

	<para id="rc2">To compute the probability of error of the
	optimal rule, write
	  <equation id="eqn6">
	  <m:math>
	    <m:apply>
	      <m:eq/>
	      <m:ci><m:msub>
		  <m:mi>P</m:mi>
		  <m:mi>e</m:mi>
		</m:msub></m:ci>
	      
	      <m:apply>
		<m:plus/>
		<m:apply>
		  <m:times/>
		  <m:ci><m:msub>
		      <m:mi>π</m:mi>
		      <m:mn>0</m:mn>
		    </m:msub></m:ci>
		  <m:apply>
		    <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#probability"/>
		    <m:condition>
		      <m:mrow>
			<m:msub>
			  <m:mi>ℋ</m:mi>
			  <m:mn>0</m:mn>
			</m:msub>
			<m:mtext> true</m:mtext>
		      </m:mrow>
		    </m:condition>
		    <m:mrow>
		      <m:mtext>declare </m:mtext>
		      <m:msub>
			<m:mi>ℋ</m:mi>
			<m:mn>1</m:mn>
		      </m:msub>
		    </m:mrow>
		  </m:apply>
		</m:apply>
		<m:apply>
		  <m:times/>
		  <m:ci><m:msub>
		      <m:mi>π</m:mi>
		      <m:mn>1</m:mn>
		    </m:msub></m:ci>
		  <m:apply>
		    <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#probability"/>
		    <m:condition>
		      <m:mrow>
			<m:msub>
			  <m:mi>ℋ</m:mi>
			  <m:mn>1</m:mn>
			</m:msub>
			<m:mtext> true</m:mtext>
		      </m:mrow>
		    </m:condition>
		    <m:mrow>
		      <m:mtext>declare </m:mtext>
		      <m:msub>
			<m:mi>ℋ</m:mi>
			<m:mn>0</m:mn>
		      </m:msub>
		    </m:mrow>
		  </m:apply>
		</m:apply>
	      </m:apply>

	      <m:apply>
		<m:plus/>
		<m:apply>
		  <m:times/>
		  <m:ci><m:msub>
		      <m:mi>π</m:mi>
		      <m:mn>0</m:mn>
		    </m:msub></m:ci>
		  <m:apply>
		    <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#probability"/>
		    <m:condition>
		      <m:mrow>
			<m:msub>
			  <m:mi>ℋ</m:mi>
			  <m:mn>0</m:mn>
			</m:msub>
			<m:mtext> true</m:mtext>
		      </m:mrow>
		    </m:condition>
		    <m:apply>
		      <m:gt/>
		      <m:ci>k</m:ci>
		      <m:ci>γ</m:ci>
		    </m:apply>
		  </m:apply>
		</m:apply>
		<m:apply>
		  <m:times/>
		  <m:ci><m:msub>
		      <m:mi>π</m:mi>
		      <m:mn>1</m:mn>
		    </m:msub></m:ci>
		  <m:apply>
		    <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#probability"/>
		    <m:condition>
		      <m:mrow>
			<m:msub>
			  <m:mi>ℋ</m:mi>
			  <m:mn>1</m:mn>
			</m:msub>
			<m:mtext> true</m:mtext>
		      </m:mrow>
		    </m:condition>
		    <m:apply>
		      <m:leq/>
		      <m:ci>k</m:ci>
		      <m:ci>γ</m:ci>
		    </m:apply>
		  </m:apply>
		</m:apply>
	      </m:apply>
	    </m:apply>
	  </m:math>
	  </equation>
	  Now <m:math><m:ci>k</m:ci></m:math> is a binomial random variable, 
	  <m:math>
	    <m:apply>
	      <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#distributedin"/>
	      <m:ci>k</m:ci>
	      <m:apply>
		<m:ci type="fn">Binomial</m:ci>
		<m:ci>N</m:ci>
		<m:ci>θ</m:ci>
	      </m:apply>
	    </m:apply>
	  </m:math>, where <m:math><m:ci>θ</m:ci></m:math>
	  depends on which hypothesis is true. We have
	  <equation id="eqn7">
	    <m:math display="block">
	      <m:apply>
		<m:eq/>
		<m:apply>
		  <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#probability"/>
		  <m:condition>
		    <m:ci>
		      <m:msub>
			<m:mi>ℋ</m:mi>
			<m:mn>0</m:mn>
		      </m:msub>
		    </m:ci>
		  </m:condition>
		  <m:apply>
		    <m:gt/>
		    <m:ci>k</m:ci>
		    <m:ci>γ</m:ci>
		  </m:apply>
		</m:apply>
		<m:apply>
		  <m:sum/>
		  <m:bvar>
		    <m:ci>k</m:ci>
		  </m:bvar>
		  <m:lowlimit>
		    <m:apply>
		      <m:plus/>
		      <m:apply>
			<m:floor/>
			<m:ci>γ</m:ci>
		      </m:apply>
		      <m:cn>1</m:cn>
		    </m:apply>
		  </m:lowlimit>
		  <m:uplimit>
		    <m:ci>N</m:ci>
		  </m:uplimit>
		  <m:apply>
		    <m:ci type="fn"><m:msub>
			<m:mi>f</m:mi>
			<m:mn>0</m:mn>
		      </m:msub></m:ci>
		    <m:ci>k</m:ci>
		  </m:apply>
		</m:apply>
		<m:apply>
		  <m:sum/>
		  <m:bvar>
		    <m:ci>k</m:ci>
		  </m:bvar>
		  <m:lowlimit>
		    <m:apply>
		      <m:plus/>
		      <m:apply>
			<m:floor/>
			<m:ci>γ</m:ci>
		      </m:apply>
		      <m:cn>1</m:cn>
		    </m:apply>
		  </m:lowlimit>
		  <m:uplimit>
		    <m:ci>N</m:ci>
		  </m:uplimit>
		  <m:apply>
		    <m:times/>
		    <m:apply>
		      <m:csymbol definitionURL="http://www.openmath.org/cd/combinat1.ocd"/>
		      <m:ci>N</m:ci>
		      <m:ci>k</m:ci>
		    </m:apply>
		    <m:apply>
		      <m:power/>
		      <m:ci>p</m:ci>
		      <m:ci>k</m:ci>
		    </m:apply>
		    <m:apply>
		      <m:power/>
		      <m:apply>
			<m:minus/>
			<m:cn>1</m:cn>
			<m:ci>p</m:ci>
		      </m:apply>
		      <m:apply>
			<m:minus/>
			<m:ci>N</m:ci>
			<m:ci>k</m:ci>
		      </m:apply>
		    </m:apply>
		  </m:apply>
		</m:apply>
	      </m:apply>
	    </m:math>
	  </equation>
	  and
	  <m:math display="block">
	    <m:apply>
	      <m:eq/>
	      <m:apply>
		<m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#probability"/>
		<m:condition>
		  <m:ci>
		    <m:msub>
		      <m:mi>ℋ</m:mi>
		      <m:mn>1</m:mn>
		    </m:msub></m:ci>
		</m:condition>
		<m:apply>
		  <m:leq/>
		  <m:ci>k</m:ci>
		  <m:ci>γ</m:ci>
		</m:apply>
	      </m:apply>
	      <m:apply>
		<m:sum/>
		<m:bvar>
		  <m:ci>k</m:ci>
		</m:bvar>
		<m:lowlimit>
		  <m:cn>0</m:cn>
		</m:lowlimit>
		<m:uplimit>
		  <m:apply>
		    <m:floor/>
		    <m:ci>γ</m:ci>
		  </m:apply>
		</m:uplimit>
		<m:apply>
		  <m:times/>
		  <m:apply>
		    <m:csymbol definitionURL="http://www.openmath.org/cd/combinat1.ocd"/>
		    <m:ci>N</m:ci>
		    <m:ci>k</m:ci>
		  </m:apply>
		  <m:apply>
		    <m:power/>
		    <m:apply>
		      <m:minus/>
		      <m:cn>1</m:cn>
		      <m:ci>p</m:ci>
		    </m:apply>
		    <m:ci>k</m:ci>
		  </m:apply>
		  <m:apply>
		    <m:power/>
		    <m:ci>p</m:ci>
		    <m:apply>
		      <m:minus/>
		      <m:ci>N</m:ci>
		      <m:ci>k</m:ci>
		    </m:apply>
		  </m:apply>
		</m:apply>
	      </m:apply>
	    </m:apply>
	  </m:math>
	  Using these formulae, we may compute
	  <m:math>
	    <m:ci><m:msub>
		<m:mi>P</m:mi>
		<m:mi>e</m:mi>
	      </m:msub></m:ci>
	  </m:math> 
	  explicitly for given values of
	  <m:math><m:ci>N</m:ci></m:math>,
	  <m:math><m:ci>p</m:ci></m:math>,
	  <m:math>
	    <m:ci><m:msub>
		<m:mi>π</m:mi>
		<m:mn>0</m:mn>
	      </m:msub></m:ci>
	  </m:math> and
	  <m:math>
	    <m:ci><m:msub>
		<m:mi>π</m:mi>
		<m:mn>1</m:mn>
	      </m:msub></m:ci>
	  </m:math>.
	  
	  <!-- Note for future: Insert applet that plots P_e as a
	  function of these parameters -->
	</para>
      </section>
    </example>

    <section id="map">
      <title>MAP Interpretation</title>

      <para id="map1">The likelihood ratio test is one way of
      expressing the minimum probability of error decision
      rule. Another way is

	<rule id="mapRule" type="Rule"><label>Rule</label>
	  <statement id="idm6517024">
	    <para id="mapRule1">Declare hypothesis
	      <m:math><m:ci>i</m:ci></m:math> such that
	      <m:math>
		<m:apply>
		  <m:times/>
		  <m:ci><m:msub>
		      <m:mi>π</m:mi>
		      <m:mi>i</m:mi>
		    </m:msub></m:ci>
		  <m:apply>
		    <m:ci type="fn"><m:msub>
			<m:mi>f</m:mi>
			<m:mi>i</m:mi>
		      </m:msub></m:ci>
		    <m:ci type="vector">x</m:ci>
		  </m:apply>
		</m:apply>
	      </m:math> is maximal.
	    </para>
	  </statement>
	</rule>

	This rule is referred to as the <term>maximum <foreign>a
	posteriori</foreign></term>, or <term>MAP</term> rule, because
	the quantity
	<m:math>
	  <m:apply>
	    <m:times/>
	    <m:ci><m:msub>
		<m:mi>π</m:mi>
		<m:mi>i</m:mi>
	      </m:msub></m:ci>
	    <m:apply>
	      <m:ci type="fn"><m:msub>
		  <m:mi>f</m:mi>
		  <m:mi>i</m:mi>
		</m:msub></m:ci>
	      <m:ci type="vector">x</m:ci>
	    </m:apply>
	  </m:apply>
	</m:math> is proportional to the posterior probability of
	hypothesis <m:math><m:ci>i</m:ci></m:math>. This becomes clear
	when we write
	<m:math>
	  <m:apply>
	    <m:eq/>
	    <m:ci><m:msub>
		<m:mi>π</m:mi>
		<m:mi>i</m:mi>
	      </m:msub></m:ci>
	    <m:apply>
	      <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#probability"/>
	      <m:ci><m:msub>
		  <m:mi>ℋ</m:mi>
		  <m:mi>i</m:mi>
		</m:msub></m:ci>
	    </m:apply>
	  </m:apply>
	</m:math> and
	<m:math>
	  <m:apply>
	    <m:eq/>
	    <m:apply>
	      <m:ci type="fn"><m:msub>
		  <m:mi>f</m:mi>
		  <m:mi>i</m:mi>
		</m:msub></m:ci>
	      <m:ci type="vector">x</m:ci>
	    </m:apply>
	    <m:apply>
	      <m:ci type="fn">f</m:ci>
	      <m:mrow>
		<m:ci type="vector">x</m:ci>
		<m:mo>|</m:mo>
		<m:msub>
		  <m:mi>ℋ</m:mi>
		  <m:mi>i</m:mi>
		</m:msub>
	      </m:mrow>
	    </m:apply>
	  </m:apply>
	</m:math>.  
	<!-- FIXME, bad connexion, missing module -->
	Then, by <link document="">Bayes rule</link>, the
	posterior probability of
	<m:math>
	  <m:ci><m:msub>
	      <m:mi>ℋ</m:mi>
	      <m:mi>i</m:mi>
	    </m:msub></m:ci>
	</m:math> given the data is
	<m:math display="block">
	  <m:apply>
	    <m:eq/>
	    <m:apply>
	      <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#probability"/>
	      <m:condition>
		<m:ci type="vector">x</m:ci>
	      </m:condition>
	      <m:ci><m:msub>
		  <m:mi>ℋ</m:mi>
		  <m:mi>i</m:mi>
		</m:msub></m:ci>
	    </m:apply>
	    <m:apply>
	      <m:divide/>
	      <m:apply>
		<m:times/>
		<m:apply>
		  <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#probability"/>
		  <m:ci><m:msub>
		      <m:mi>ℋ</m:mi>
		      <m:mi>i</m:mi>
		    </m:msub></m:ci>
		</m:apply>
		<m:apply>
		  <m:ci type="fn">f</m:ci>
		  <m:mrow>
		    <m:ci type="vector">x</m:ci>
		    <m:mo>|</m:mo>
		    <m:msub>
		      <m:mi>ℋ</m:mi>
		      <m:mi>i</m:mi>
		    </m:msub>
		  </m:mrow>
		</m:apply>
	      </m:apply>
	      <m:apply>
		<m:ci type="fn">f</m:ci>
		<m:ci type="vector">x</m:ci>
	      </m:apply>
	    </m:apply>
	  </m:apply>
	</m:math>
	Here
	<m:math>
	  <m:apply>
	    <m:ci type="fn">f</m:ci>
	    <m:ci type="vector">x</m:ci>
	  </m:apply>
	</m:math> is the unconditional density or mass function for
	<m:math><m:ci type="vector">x</m:ci></m:math>, which is
	effectively a constant when trying to maximiaze with respect to
	<m:math><m:ci>i</m:ci></m:math>.
      </para>

      <para id="map2">According to the MAP interpretation, the optimal
      decision boundary is the locus of points where the weighted
      densities (in the continuous case)
	<m:math>
	  <m:apply>
	    <m:times/>
	    <m:ci><m:msub>
		<m:mi>π</m:mi>
		<m:mi>i</m:mi>
	      </m:msub></m:ci>
	    <m:apply>
	      <m:ci type="fn"><m:msub>
		  <m:mi>f</m:mi>
		  <m:mi>i</m:mi>
		</m:msub></m:ci>
	      <m:ci>x</m:ci>
	    </m:apply>
	  </m:apply>
	</m:math> intersect one another. This idea is illustrated in
	<link target-id="ex2"/>.
      </para>
    </section>

    <section id="mh">
      <title>Multiple Hypotheses</title>

      <para id="mh1">One advantage the MAP formulation of the minimum
      probability of error decision rule has over the LRT is that it
      generalizes easily to <m:math><m:ci>M</m:ci></m:math>-ary
      hypothesis testing. If we are to choose between hypotheses
	<m:math>
	  <m:ci><m:msub>
	      <m:mi>ℋ</m:mi>
	      <m:mi>i</m:mi>
	    </m:msub></m:ci>
	</m:math>, 
	<m:math>
	  <m:apply>
	    <m:eq/>
	    <m:ci>i</m:ci>
	    <m:set>
	      <m:cn>1</m:cn>
	      <m:ci>…</m:ci>
	      <m:ci>M</m:ci>
	    </m:set>
	  </m:apply>
	</m:math>, the optimal rule is still the <link target-id="mapRule">MAP rule</link>
	<!-- Note: Future versions of this module should add
	examples/problems on M-ary tests -->
      </para>
    </section>

    <section id="scbr">
      <title>Special Case of Bayes Risk</title> <para id="scbr1">The
      <link document="m11533">Bayes risk criterion</link> for
      constructing decision rules assigns a cost
	<m:math>
	  <m:ci><m:msub>
	      <m:mi>C</m:mi>
	      <m:mrow>
		<m:mi>i</m:mi>
		<m:mo>​</m:mo>
		<m:mi>j</m:mi>
	      </m:mrow>
	    </m:msub></m:ci>
	</m:math> to the outcome of declaring
	<m:math>
	  <m:ci><m:msub>
	      <m:mi>ℋ</m:mi>
	      <m:mi>i</m:mi>
	    </m:msub></m:ci>
	</m:math> when
	<m:math>
	  <m:ci><m:msub>
	      <m:mi>ℋ</m:mi>
	      <m:mi>j</m:mi>
	    </m:msub></m:ci>
	</m:math> 
	is in effect. The probability of error is simply a special
	case of the Bayes risk corresponding to
	<m:math>
	  <m:apply>
	    <m:eq/>
	    <m:ci><m:msub>
		<m:mi>C</m:mi>
		<m:mn>00</m:mn>
	      </m:msub></m:ci>
	    <m:ci><m:msub>
		<m:mi>C</m:mi>
		<m:mn>11</m:mn>
	      </m:msub></m:ci>
	    <m:cn>0</m:cn>
	  </m:apply>
	</m:math> and
	<m:math>
	  <m:apply>
	    <m:eq/>
	    <m:ci><m:msub>
		<m:mi>C</m:mi>
		<m:mn>01</m:mn>
	      </m:msub></m:ci>
	    <m:ci><m:msub>
		<m:mi>C</m:mi>
		<m:mn>10</m:mn>
	      </m:msub></m:ci>
	    <m:cn>1</m:cn>
	  </m:apply>
	</m:math>. Therefore, the form of the minimum probability of
	error decision rule is a specialization of the minimum Bayes
	risk decision rule: both are likelihood ratio tests. The
	different costs in the Bayes risk formulation simply shift the
	threshold to favor one hypothesis over the other.
      </para>
    </section>

    <section id="probs">
      <title>Problems</title>

      <exercise id="exer1">
	<problem id="idp500912">
	  <para id="e1p1">Generally speaking, when is the probability of
	    error <emphasis>zero</emphasis> for the optimal rule? Phrase
	    your answer in terms of the distributions underlying each
	    hypothesis. Does the LRT agree with your answer in this case?
	  </para>
	</problem>
      </exercise>

      <exercise id="exer2">
	<problem id="idp3453168">
	  <para id="e2p1">Suppose we measure
	    <m:math><m:ci>N</m:ci></m:math> independent values
	    <m:math>
	      <m:mrow>
		<m:msub>
		  <m:mi>x</m:mi>
		  <m:mn>1</m:mn>
		</m:msub>
		<m:mo>,</m:mo>
		<m:mi>…</m:mi>
		<m:mo>,</m:mo>
		<m:msub>
		  <m:mi>x</m:mi>
		  <m:mi>N</m:mi>
		</m:msub>
	      </m:mrow>
	    </m:math>. We know the variance of our measurements 
	    (<m:math>
	      <m:apply>
		<m:eq/>
		<m:apply>
		  <m:power/>
		  <m:ci>σ</m:ci>
		  <m:cn>2</m:cn>
		</m:apply>
		<m:cn>1</m:cn>
	      </m:apply>
	    </m:math>), but are unsure whether the data obeys a
	    Laplacian or Gaussian probability law:
	    <m:math display="block">
	      <m:mrow>
		<m:msub>
		  <m:mi>ℋ</m:mi>
		  <m:mn>0</m:mn>
		</m:msub>
		<m:mo>:</m:mo>
		<m:apply>
		  <m:eq/>
		  <m:apply>
		    <m:ci type="fn"><m:msub>
			<m:mi>f</m:mi>
			<m:mn>0</m:mn>
		      </m:msub></m:ci>
		    <m:ci>x</m:ci>
		  </m:apply>
		  <m:apply>
		    <m:times/>
		    <m:apply>
		      <m:divide/>
		      <m:cn>1</m:cn>
		      <m:apply>
			<m:root/>
			<m:cn>2</m:cn>
		      </m:apply>
		    </m:apply>
		    <m:apply>
		      <m:exp/>
		      <m:apply>
			<m:minus/>
			<m:apply>
			  <m:times/>
			  <m:apply>
			    <m:root/>
			    <m:cn>2</m:cn>
			  </m:apply>
			  <m:apply>
			    <m:abs/>
			    <m:ci>r</m:ci>
			  </m:apply>
			</m:apply>
		      </m:apply>
		    </m:apply>
		  </m:apply>
		</m:apply>
	      </m:mrow>
	    </m:math>
	    <m:math display="block">
	      <m:mrow>
		<m:msub>
		  <m:mi>ℋ</m:mi>
		  <m:mn>1</m:mn>
		</m:msub>
		<m:mo>:</m:mo>
		<m:apply>
		  <m:eq/>
		  <m:apply>
		    <m:ci type="fn"><m:msub>
			<m:mi>f</m:mi>
			<m:mn>1</m:mn>
		      </m:msub></m:ci>
		    <m:ci>x</m:ci>
		  </m:apply>
		  <m:apply>
		    <m:times/>
		    <m:apply>
		      <m:divide/>
		      <m:cn>1</m:cn>
		      <m:apply>
			<m:root/>
			<m:apply>
			  <m:times/>
			  <m:cn>2</m:cn>
			  <m:pi/>
			</m:apply>
		      </m:apply>
		    </m:apply>
		    <m:apply>
		      <m:exp/>
		      <m:apply>
			<m:minus/>
			<m:apply>
			  <m:divide/>
			  <m:apply>
			    <m:power/>
			    <m:ci>r</m:ci>
			    <m:cn>2</m:cn>
			  </m:apply>
			  <m:cn>2</m:cn>
			</m:apply>
		      </m:apply>
		    </m:apply>
		  </m:apply>
		</m:apply>
	      </m:mrow>
	    </m:math>
	  </para>

	  <section id="parta">
	    <para id="partap">Show that the two densities have the same
	      mean and variance, and plot the densities on the same
	      graph.</para>
	  </section>

	  <section id="partb">
	    <para id="partbp">Find the likelihood ratio.</para>
	  </section>

	  <section id="partc">
	    <para id="partcp">Determine the decision regions for
	      different values of the threshold
	      <m:math><m:ci>η</m:ci></m:math>. Consider all possible
	      values of
	      <m:math>
		<m:apply>
		  <m:gt/>
		  <m:ci>η</m:ci>
		  <m:cn>0</m:cn>
		</m:apply>
	      </m:math>
	      <note type="hint" id="idm6307872"><label>Hint</label>There are three distinct cases.</note></para>
	  </section>

	  <section id="partd">
	    <para id="partdp">Draw the decision regions and decision
	      boundaries for
	      <m:math>
		<m:apply>
		  <m:eq/>
		  <m:ci>η</m:ci>
		  <m:set>
		    <m:apply>
		      <m:divide/>
		      <m:cn>1</m:cn>
		      <m:cn>2</m:cn>
		    </m:apply>
		    <m:cn>1</m:cn>
		    <m:cn>2</m:cn>
		  </m:set>
		</m:apply>
	      </m:math>.</para>
	  </section>

	  <section id="parte">
	    <para id="partep">Assuming the two hypotheses are equally
	      likely, compute the probability of error. Your answer should
	      be a number.
	    </para>
	  </section>
	</problem>
      </exercise>
      
      <exercise id="exer3">
	<problem id="idm5723264">
	  <section id="e3s1">
	    <title>Arbitrary Means and Covariances</title>

	    <para id="e3p1">Consider the hypothesis testing problem
	      <m:math display="block">
		<m:mrow>
		  <m:msub>
		    <m:mi>ℋ</m:mi>
		    <m:mn>0</m:mn>
		  </m:msub>
		  <m:mo>:</m:mo>
		  <m:apply>
		    <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#distributedin"/>
		    <m:ci type="vector">x</m:ci>
		    <m:apply>
		      <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#normaldistribution"/>
		      <m:ci type="vector"><m:msub>
			  <m:mi>μ</m:mi>
			  <m:mn>0</m:mn>
			</m:msub></m:ci>
		      <m:ci type="matrix"><m:msub>
			  <m:mi>Σ</m:mi>
			  <m:mn>0</m:mn>
			</m:msub></m:ci>
		    </m:apply>
		  </m:apply>
		</m:mrow>
	      </m:math>
	      <m:math display="block">
		<m:mrow>
		  <m:msub>
		    <m:mi>ℋ</m:mi>
		    <m:mn>1</m:mn>
		  </m:msub>
		  <m:mo>:</m:mo>
		  <m:apply>
		    <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#distributedin"/>
		    <m:ci type="vector">x</m:ci>
		    <m:apply>
		      <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#normaldistribution"/>
		      <m:ci type="vector"><m:msub>
			  <m:mi>μ</m:mi>
			  <m:mn>1</m:mn>
			</m:msub></m:ci>
		      <m:ci type="matrix"><m:msub>
			  <m:mi>Σ</m:mi>
			  <m:mn>1</m:mn>
			</m:msub></m:ci>
		    </m:apply>
		  </m:apply>
		</m:mrow>
	      </m:math>
	      where
	      <m:math>
		<m:apply>
		  <m:in/>
		  <m:ci type="vector"><m:msub>
		      <m:mi>μ</m:mi>
		      <m:mn>0</m:mn>
		    </m:msub></m:ci>
		  <m:apply>
		    <m:power/>
		    <m:reals/>
		    <m:ci>d</m:ci>
		  </m:apply>
		</m:apply>
	      </m:math> and
	      <m:math>
		<m:apply>
		  <m:in/>
		  <m:ci type="vector"><m:msub>
		      <m:mi>μ</m:mi>
		      <m:mn>0</m:mn>
		    </m:msub></m:ci>
		  <m:apply>
		    <m:power/>
		    <m:reals/>
		    <m:ci>d</m:ci>
		  </m:apply>
		</m:apply>
	      </m:math>, and
	      <m:math>
		<m:ci type="matrix"><m:msub>
		    <m:mi>Σ</m:mi>
		    <m:mn>0</m:mn>
		  </m:msub></m:ci>
	      </m:math>,
	      <m:math>
		<m:ci type="matrix"><m:msub>
		    <m:mi>Σ</m:mi>
		    <m:mn>1</m:mn>
		  </m:msub></m:ci>
	      </m:math> 
	      are positive definite, symmetric
	      <m:math><m:ci>d</m:ci></m:math>×<m:math>
		<m:ci>d</m:ci></m:math> matrices. Write down the 
	      likelihood ratio test, and simplify, for the following 
	      cases. In each case, provide a geometric description 
	      of the decision boundary.
	    </para>
	    
	    <section id="s3.1">
	      <para id="p3.1">
		<m:math>
		  <m:apply>
		    <m:eq/>
		    <m:ci type="matrix"><m:msub>
			<m:mi>Σ</m:mi>
			<m:mn>0</m:mn>
		      </m:msub></m:ci>
		    <m:ci type="matrix"><m:msub>
			<m:mi>Σ</m:mi>
			<m:mn>1</m:mn>
		      </m:msub></m:ci>
		  </m:apply>
		</m:math>, but
		<m:math>
		  <m:apply>
		    <m:neq/>
		    <m:ci type="vector"><m:msub>
			<m:mi>μ</m:mi>
			<m:mn>0</m:mn>
		      </m:msub></m:ci>
		    <m:ci type="vector"><m:msub>
			<m:mi>μ</m:mi>
			<m:mn>1</m:mn>
		      </m:msub></m:ci>
		  </m:apply>
		</m:math>.
	      </para>
	    </section>

	    <section id="s3.2">
	      <para id="p3.2">
		<m:math>
		  <m:apply>
		    <m:eq/>
		    <m:ci type="vector"><m:msub>
			<m:mi>μ</m:mi>
			<m:mn>0</m:mn>
		      </m:msub></m:ci>
		    <m:ci type="vector"><m:msub>
			<m:mi>μ</m:mi>
			<m:mn>1</m:mn>
		      </m:msub></m:ci>
		  </m:apply>
		</m:math>, but
		<m:math>
		  <m:apply>
		    <m:neq/>
		    <m:ci type="matrix"><m:msub>
			<m:mi>Σ</m:mi>
			<m:mn>0</m:mn>
		      </m:msub></m:ci>
		    <m:ci type="matrix"><m:msub>
			<m:mi>Σ</m:mi>
			<m:mn>1</m:mn>
		      </m:msub></m:ci>
		  </m:apply>
		</m:math>.</para>
	    </section>

	    <section id="s3.3">
	      <para id="p3.3">
		<m:math>
		  <m:apply>
		    <m:neq/>
		    <m:ci type="vector"><m:msub>
			<m:mi>μ</m:mi>
			<m:mn>0</m:mn>
		      </m:msub></m:ci>
		    <m:ci type="vector"><m:msub>
			<m:mi>μ</m:mi>
			<m:mn>1</m:mn>
		      </m:msub></m:ci>
		  </m:apply>
		</m:math> and
		<m:math>
		  <m:apply>
		    <m:neq/>
		    <m:ci type="matrix"><m:msub>
			<m:mi>Σ</m:mi>
			<m:mn>0</m:mn>
		      </m:msub></m:ci>
		    <m:ci type="matrix"><m:msub>
			<m:mi>Σ</m:mi>
			<m:mn>1</m:mn>
		      </m:msub></m:ci>
		  </m:apply>
		</m:math>.</para>
	    </section>
	  </section>
	</problem>
      </exercise>

      <exercise id="exer4">
	<problem id="idp2886784">
	  <para id="p4.0">Suppose we observe
	    <m:math><m:ci>N</m:ci></m:math> independent realizations of a
	    Poisson random variable <m:math><m:ci>k</m:ci></m:math> with
	    intensity parameter <m:math><m:ci>λ</m:ci></m:math>:
	    <m:math display="block">
	      <m:apply>
		<m:eq/>
		<m:apply>
		  <m:ci type="fn">f</m:ci>
		  <m:ci>k</m:ci>
		</m:apply>
		<m:apply>
		  <m:divide/>
		  <m:apply>
		    <m:times/>
		    <m:apply>
		      <m:exp/>
		      <m:apply>
			<m:minus/>
			<m:ci>λ</m:ci>
		      </m:apply>
		    </m:apply>
		    <m:apply>
		      <m:power/>
		      <m:ci>λ</m:ci>
		      <m:ci>k</m:ci>
		    </m:apply>
		  </m:apply>
		  <m:apply>
		    <m:factorial/>
		    <m:ci>k</m:ci>
		  </m:apply>
		</m:apply>
	      </m:apply>
	    </m:math>
	    We must decide which of two intensities is in effect:
	    <m:math display="block">
	      <m:mrow>
		<m:msub>
		  <m:mi>ℋ</m:mi>
		  <m:mn>0</m:mn>
		</m:msub>
		<m:mo>:</m:mo>
		<m:apply>
		  <m:eq/>
		  <m:ci>λ</m:ci>
		  <m:ci><m:msub>
		      <m:mi>λ</m:mi>
		      <m:mn>0</m:mn>
		    </m:msub></m:ci>
		</m:apply>
	      </m:mrow>
	    </m:math>
	    <m:math display="block">
	      <m:mrow>
		<m:msub>
		  <m:mi>ℋ</m:mi>
		  <m:mn>1</m:mn>
		</m:msub>
		<m:mo>:</m:mo>
		<m:apply>
		  <m:eq/>
		  <m:ci>λ</m:ci>
		  <m:ci><m:msub>
		      <m:mi>λ</m:mi>
		      <m:mn>1</m:mn>
		    </m:msub></m:ci>
		</m:apply>
	      </m:mrow>
	    </m:math>
	    where
	    <m:math>
	      <m:apply>
		<m:lt/>
		<m:ci><m:msub>
		    <m:mi>λ</m:mi>
		    <m:mn>0</m:mn>
		  </m:msub></m:ci>
		<m:ci><m:msub>
		    <m:mi>λ</m:mi>
		    <m:mn>1</m:mn>
		  </m:msub></m:ci>
	      </m:apply>
	    </m:math>.
	  </para>

	  <section id="s4.1">
	    <para id="p4.1">Give the minimum probability of error
	      decision rule.</para>
	  </section>

	  <section id="s4.2">
	    <para id="p4.2">Simplify the LRT to a test statistic
	      involving only a sufficient statistic. Apply a monotonically
	      increasing transformation to simplify further.</para>
	  </section>

	  <section id="s4.3">
	    <para id="p4.3">Determine the distribution of the sufficient
	      statistic under both hypotheses. <note type="Hint" id="idm488064"><label>Hint</label>Use the
		characteristic function to show that a sum of IID Poisson
		variates is again Poisson distributed.</note></para>
	  </section>

	  <section id="s4.4">
	    <para id="p4.4">Derive an expression for the probability of
	      error.
	    </para>
	  </section>

	  <section id="s4.5">
	    <para id="p4.5">Assuming the two hypotheses are equally likely, and
	      <m:math>
		<m:apply>
		  <m:eq/>
		  <m:ci><m:msub>
		      <m:mi>λ</m:mi>
		      <m:mn>0</m:mn>
		    </m:msub></m:ci>
		  <m:cn>5</m:cn>
		</m:apply>
	      </m:math> and
	      <m:math>
		<m:apply>
		  <m:eq/>
		  <m:ci><m:msub>
		      <m:mi>λ</m:mi>
		      <m:mn>1</m:mn>
		    </m:msub></m:ci>
		  <m:cn>6</m:cn>
		</m:apply>
	      </m:math>, what is the minimum number
	      <m:math><m:ci>N</m:ci></m:math> of observations needed to
	      attain a probability of error no greater than 0.01? <note type="Hint" id="idp3039552"><label>Hint</label>If you have numerical trouble, try rewriting
		the log-factorial so as to avoid evaluating the factorial
		of large integers.</note></para>
	  </section>
	</problem>
      </exercise>

      <exercise id="ex5">
	<problem id="idp1755472">
	  <para id="ex5para1">In <link target-id="ex3"/>, suppose
	    <m:math>
	      <m:apply>
		<m:eq/>
		<m:ci><m:msub>
		    <m:mi>π</m:mi>
		    <m:mn>0</m:mn>
		  </m:msub></m:ci>
		<m:ci><m:msub>
		    <m:mi>π</m:mi>
		    <m:mn>1</m:mn>
		  </m:msub></m:ci>
		<m:apply>
		  <m:divide/>
		  <m:cn>1</m:cn>
		  <m:cn>2</m:cn>
		</m:apply>
	      </m:apply>
	    </m:math>, and
	    <m:math>
	      <m:apply>
		<m:eq/>
		<m:ci>p</m:ci>
		<m:cn>0.1</m:cn>
	      </m:apply>
	    </m:math>. What is the smallest value of
	    <m:math><m:ci>N</m:ci></m:math> needed to ensure
	    <m:math>
	      <m:apply>
		<m:leq/>
		<m:ci><m:msub>
		    <m:mi>P</m:mi>
		    <m:mi>e</m:mi>
		  </m:msub></m:ci>
		<m:cn>0.01</m:cn>
	      </m:apply>
	    </m:math>?
	  </para>
	</problem>
      </exercise>
    </section>

  </content>
  
</document>